---
title: "Introduction to CUDA Programming"
excerpt: ""
date: 2024-05-30 08:00:00 +0900
header:
  overlay_image: /assets/images/unsplash-thomas-t-math.jpg
  overlay_filter: 0.5
  caption: "Photo by [**Thomas T**](https://unsplash.com/@pyssling240) on [**Unsplash**](https://unsplash.com/)"
categories:
  - CUDA
mathjax: "true"
---

## CUDA

- **CUDA(Compute Unified Device Architecture)**: A parallel computing platform and application programming interface(API) model created by NVIDIA.
- **GPGPU**: General Purpose Computing in Graphics Processing Units

## Environment

환경

- Windows 11
- NVIDIA GeForce 4080 Super

### Install한 것

1. Visual Studio 2022 Community
2. NVIDIA driver 555.85
3. CUDA Toolkit 12.5

## Basic steps of a CUDA program

1. CPU에서 data initialization
2. CPU context에서 GPU context로 data transfer
3. 필요한 grid/block size로 kernel launch
4. GPU context에서 CPU context로 result transfer
5. CPU와 GPU에서 memory 해제

### CUDA program elements

- Host code(main fuction): CPU에서 수행되는 코드, cuda kernel 호출, device configuration 관리
- Device code: GPU에서 수행되는 코드

## CUDA Hello World

- `__global__`, `__device__`, `__host__` 함수 선언 시 사용되는 키워드
- 모든 kernel은 리턴 타입으로 `void`를 사용해야 함
- Kernel code 호출 형식은 `kernel_name<<<grid_size, block_size>>>(args)`ㅣ이다.
- kernel 호출 시 함수가 block 되지 않으며, 종료를 기다리기 위해서는 `cudaDeviceSynchronize()`를 사용해야 한다. 그러면 이전에 실행된 모든 kernel이 종료될 때까지 기다린다.
- kernel 실행이 종료되면 일반적으로는 GPU에서 CPU로 결과 데이터를 복사한다.
- 우리 예제에서는 출력만 수행하므로 `cudaDeviceReset()` 만 호출한다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
  printf("Hello CUDA world!\n");
}

int main() {
  hello_cuda<<<1, 1>>>();
  cudaDeviceSynchronize();
  cudaDeviceReset();
  return 0;
}
```

- Kernel launch parameter를 변경할 수 있다. 예를 들어 `hello_cuda<<<1, 20>>>();`을 호출하면 20개의 thread가 실행되어 20개의 "Hello CUDA world!"가 출력된다.

### Grid and Block

- Grid: A collection of all the threads launch for a kernel
- Block: Threads in a grid is organized into groups called thread blocks

```cpp
kenel_name<<<number_of_blocks, threads_per_block>>>(arguments);
```

- `number_of_blocks`와 `threads_per_block`은 dimension을 가질 수 있으며 `dim3` 타입으로 선언할 수 있다. 큐브 형태로 Thread가 존재한다고 생각하면 된다.

```cpp
dim3 variable_name(X, Y, Z);

variable_name.x;
variable_name.y;
variable_name.z;
```

dimension을 명시하지 않으면 기본값은 1이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
    printf("Hello CUDA world!\n");
}

int main() {
    dim3 block(4); // x = 4, y = 1, z = 1
    dim3 grid(8); // x = 8, y = 1, z = 1

    hello_cuda << <grid, block >> > (); // print 32 times
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

y dimension을 추가하는 예제이다. grid의 크기가 dynamic하게 할당된 것을 확인할 수 있다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
    printf("Hello CUDA world!\n");
}

int main() {
    int nx, ny;
    nx = 16;
    ny = 4;

    dim3 block(8, 2);
    dim3 grid(nx / block.x, ny / block.y);

    hello_cuda << <grid, block >> > (); //  print 64 times
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

### Limitation for thread block size

- `x <= 1024`, `y <= 1024`, `z <= 64`
- `x * y * z <= 1024`

### Limitation for number of thread blocks

- `x <= 2^32 - 1`, `y <= 65536`, `z <= 65536`

## `threadIdx`

- `threadIdx`는 block 내에서 thread의 index를 나타낸다.

```
threads:      |A B C D E F G H|
threadIdx.x:   0 1 2 3 4 5 6 7
threadIdx.y:   0 0 0 0 0 0 0 0
threadIdx.z:   0 0 0 0 0 0 0 0


threads:      |A B C D| |E F G H|
threadIdx.x:   0 1 2 3   0 1 2 3
threadIdx.y:   0 0 0 0   0 0 0 0
threadIdx.z:   0 0 0 0   0 0 0 0


threads:      |P ? Q ?| |? R ? S|

              |T ? U ?| |V ? ? W|

threads:       P Q R S T U V W
threadIdx.x:   0 2 1 3 0 2 0 3
threadIdx.y:   0 0 0 0 0 0 0 0


threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

threads:       X Y P Q R S T U
threadIdx.x:   1 1 0 2 0 3 1 2
threadIdx.y:   0 1 0 1 0 1 0 1
```

다음은 `threadIdx`를 이용한 간단한 예제이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void print_threadIds() {
    printf("threadIdx.x: %d, threadIdx.y: %d, threadIdx.z: %d\n",
        threadIdx.x, threadIdx.y, threadIdx.z);
}

int main() {
    int nx, ny;
    nx = 16;
    ny = 16;

    dim3 block(8, 8);
    dim3 grid(nx / block.x, ny / block.y);

    print_threadIds<< <grid, block >> > ();
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
threadIdx.x: 0, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 1, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 2, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 3, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 4, threadIdx.y: 0, threadIdx.z: 0
...
threadIdx.x: 3, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 4, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 5, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 6, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 7, threadIdx.y: 7, threadIdx.z: 0
```

## `blockIdx`

CUDA runtime inialize `blockIdx` variable for each thread depending on the coordinates of the belonging thread block in the grid.

`blockIdx`는 `dim3` 타입이다.

```
threads:      |A B C D| |E F G H|
blockIdx.x:    0 0 0 0   1 1 1 1
blockIdx.y:    0 0 0 0   0 0 0 0
blockIdx.z:    0 0 0 0   0 0 0 0


threads:      |P ? Q ?| |? R ? S|

              |T ? U ?| |V ? ? W|

threads:       P Q R S T U V W
blockIdx.x:    0 0 1 1 0 0 1 1
blockIdx.y:    0 0 0 0 1 1 1 1
blockIdx.z:    0 0 0 0 0 0 0 0

threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

threads:       X Y P Q R S T U
blockIdx.x:    0 0 1 1 0 0 1 1
blockIdx.y:    0 0 0 0 1 1 1 1
blockIdx.z:    0 0 0 0 0 0 0 0
```

## `blockDim`

`blockDim`은 thread block의 dimension을 나타낸다. 모든 block은 같은 dimension을 가진다.

```
threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

blockDim.x = 4, blockDim.y = 2
```

## `gridDim`

`gridDim`은 grid의 각 dimension의 thread block의 수를 나타낸다.

```
threads:      |? X ? ?| |P ? ? ?| |? ? ? ?|
              |? Y ? ?| |? ? Q ?| |? ? ? ?|

              |R ? ? ?| |? T ? ?| |? ? ? ?|
              |? ? ? S| |U ? ? ?| |? ? ? ?|

gridDim.x = 3, gridDim.y = 2
```

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void print_threadIds() {
    printf("blockIdx.x: %d, blockIdx.y: %d, blockIdx.z: %d, blockDim.x: %d, blockDim.y: %d, blockDim.z: %d, gridDim.x: %d, gridDim.y: %d\n",
        blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z, gridDim.x, gridDim.y);

}

int main() {
    int nx, ny;
    nx = 16;
    ny = 16;

    dim3 block(8, 8);
    dim3 grid(nx / block.x, ny / block.y);

    print_threadIds<< <grid, block >> > ();
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
...
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
```

`blockDim`과 `gridDim`은 모든 block에서 동일한 것을 확인할 수 있다.

## Unique index calculation

thread에서 index를 기반으로 데이터에 접근하는 예시이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_idx_calc_threadIdx(int* input) {
    int tid = threadIdx.x;
    printf("threadIdx: %d, value: %d\n", tid, input[tid]);
}

int main() {
    int array_size = 8;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33 };

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(8);
    dim3 grid(1);

    unique_idx_calc_threadIdx << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33

threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
threadIdx: 4, value: 65
threadIdx: 5, value: 12
threadIdx: 6, value: 1
threadIdx: 7, value: 33
```

이번엔 블록을 2개로 늘려보자.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_idx_calc_threadIdx(int* input) {
    int tid = threadIdx.x;
    printf("threadIdx: %d, value: %d\n", tid, input[tid]);
}

int main() {
    int array_size = 8;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33 };

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(2);

    unique_idx_calc_threadIdx << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33

threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
```

동일한 value가 두 번 출력되는 것을 확인할 수 있다.

```
threads:      |A B C D| |E F G H| |I J K L| |M N O P|
tid:           0 1 2 3   0 1 2 3   0 1 2 3   0 1 2 3

gid:           0 1 2 3   4 5 6 7   8 9 1 1   1 1 1 1
                                       0 1   2 3 4 5

gid = tid + offset
gid = tid + blockIdx.x * blockDim.x
```

`gid`를 이용하여 data에 접근하도록 만들자.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation(int* input) {
	int tid = threadIdx.x;
	int offset = blockIdx.x * blockDim.x;
	int gid = tid + offset;
	printf("blockIdx.x: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(4);

    unique_gid_calculation << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 3, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 3, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 3, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 3, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 2, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 2, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 2, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 2, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, threadIdx.x: 3, gid: 3, value: 53
```

## Unique index calculation for 2D grid

1D는 다음과 같이 계산할 수 있었다.

```cpp
index = blockIdx.x * blockDim.x + threadIdx.x;
```

이는 `x` dimension만 고려한 것이다. `grid`를 `grid(2, 2)`로 변경하면 잘못된 결과가 나온다.

다음과 같이 수정이 필요하다.

```cpp
gid = gridDim.x * blockDim.x * blockIdx.y  // Row offset
    + blockDim.x * blockIdx.x              // Block offset
    + threadIdx.x;
```

다음은 전체 소스코드이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation(int* input) {
  int tid = threadIdx.x;
  int block_offset = blockIdx.x * blockDim.x;
  int row_offset = gridDim.x * blockDim.x * blockIdx.y;
  int gid = row_offset + block_offset + tid;
  printf("blockIdx.x: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
      printf("%d ", h_data[i]);
    }
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(2, 2);

    unique_gid_calculation << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 1, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 1, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 1, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 1, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 0, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 0, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 0, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 0, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, threadIdx.x: 3, gid: 3, value: 53
```

앞의 예제에서는 각 block이 1D였다. 이번에는 block이 2D인 경우를 생각해보자.

```
------------------> X
. | 0  1| | 4  5|
. | 2  3| | 6  7|
.
. | 8  9| |12 13|
. |10 11| |14 15|
Y
```

이 경우 `tid`가 2D로 변경되어야 한다. `block_offset`과 `row_offset`도 block size를 고려하여 변경되어야 한다.

```cpp
tid = threadIdx.y * blockDim.x + threadIdx.x;

block_offset = number_of_threads_in_a_block * blockIdx.x;
block_offset = (blockDim.x * blockDim.y) * blockIdx.x;

row_offset = number_of_threads_in_a_row * blockIdx.y;
row_offset = (blockDim.x * blockDim.y * gridDim.x) * blockIdx.y;
```

소스 코드는 다음과 같다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation_2d_2d(int* input) {
    int tid = blockDim.x * threadIdx.y + threadIdx.x;

    int num_threads_in_a_block = blockDim.x * blockDim.y;
    int block_offset = num_threads_in_a_block * blockIdx.x;

    int num_threads_in_a_row = num_threads_in_a_block * gridDim.x;
    int row_offset = num_threads_in_a_row * blockIdx.y;

    int gid = row_offset + block_offset + tid;
    printf("blockIdx.x: %d, blockIdx.y: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, blockIdx.y, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
        printf("%d ", h_data[i]);
    }
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(2, 2);
    dim3 grid(2, 2);

    unique_gid_calculation_2d_2d << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 3, gid: 3, value: 53
```

## Memory transfer between host and device

![Memory transfer]({{site.baseurl}}/assets/images/2024-05-30-memory-transfer.drawio.svg){: .align-center}
