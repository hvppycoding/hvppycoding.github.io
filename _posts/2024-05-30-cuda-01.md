---
title: "Introduction to CUDA Programming"
excerpt: ""
date: 2024-05-30 08:00:00 +0900
header:
  overlay_image: /assets/images/unsplash-thomas-t-math.jpg
  overlay_filter: 0.5
  caption: "Photo by [**Thomas T**](https://unsplash.com/@pyssling240) on [**Unsplash**](https://unsplash.com/)"
categories:
  - CUDA
mathjax: "true"
---

## CUDA

- **CUDA(Compute Unified Device Architecture)**: A parallel computing platform and application programming interface(API) model created by NVIDIA.
- **GPGPU**: General Purpose Computing in Graphics Processing Units

## Environment

환경

- Windows 11
- NVIDIA GeForce 4080 Super

### Install한 것

1. Visual Studio 2022 Community
2. NVIDIA driver 555.85
3. CUDA Toolkit 12.5

## Basic steps of a CUDA program

1. CPU에서 data initialization
2. CPU context에서 GPU context로 data transfer
3. 필요한 grid/block size로 kernel launch
4. GPU context에서 CPU context로 result transfer
5. CPU와 GPU에서 memory 해제

### CUDA program elements

- Host code(main fuction): CPU에서 수행되는 코드, cuda kernel 호출, device configuration 관리
- Device code: GPU에서 수행되는 코드

## CUDA Hello World

- `__global__`, `__device__`, `__host__` 함수 선언 시 사용되는 키워드
- 모든 kernel은 리턴 타입으로 `void`를 사용해야 함
- Kernel code 호출 형식은 `kernel_name<<<grid_size, block_size>>>(args)`ㅣ이다.
- kernel 호출 시 함수가 block 되지 않으며, 종료를 기다리기 위해서는 `cudaDeviceSynchronize()`를 사용해야 한다. 그러면 이전에 실행된 모든 kernel이 종료될 때까지 기다린다.
- kernel 실행이 종료되면 일반적으로는 GPU에서 CPU로 결과 데이터를 복사한다.
- 우리 예제에서는 출력만 수행하므로 `cudaDeviceReset()` 만 호출한다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
  printf("Hello CUDA world!\n");
}

int main() {
  hello_cuda<<<1, 1>>>();
  cudaDeviceSynchronize();
  cudaDeviceReset();
  return 0;
}
```

- Kernel launch parameter를 변경할 수 있다. 예를 들어 `hello_cuda<<<1, 20>>>();`을 호출하면 20개의 thread가 실행되어 20개의 "Hello CUDA world!"가 출력된다.

### Grid and Block

- Grid: A collection of all the threads launch for a kernel
- Block: Threads in a grid is organized into groups called thread blocks

```cpp
kenel_name<<<number_of_blocks, threads_per_block>>>(arguments);
```

- `number_of_blocks`와 `threads_per_block`은 dimension을 가질 수 있으며 `dim3` 타입으로 선언할 수 있다. 큐브 형태로 Thread가 존재한다고 생각하면 된다.

```cpp
dim3 variable_name(X, Y, Z);

variable_name.x;
variable_name.y;
variable_name.z;
```

dimension을 명시하지 않으면 기본값은 1이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
    printf("Hello CUDA world!\n");
}

int main() {
    dim3 block(4); // x = 4, y = 1, z = 1
    dim3 grid(8); // x = 8, y = 1, z = 1

    hello_cuda << <grid, block >> > (); // print 32 times
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

y dimension을 추가하는 예제이다. grid의 크기가 dynamic하게 할당된 것을 확인할 수 있다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void hello_cuda() {
    printf("Hello CUDA world!\n");
}

int main() {
    int nx, ny;
    nx = 16;
    ny = 4;

    dim3 block(8, 2);
    dim3 grid(nx / block.x, ny / block.y);

    hello_cuda << <grid, block >> > (); //  print 64 times
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

### Limitation for thread block size

- `x <= 1024`, `y <= 1024`, `z <= 64`
- `x * y * z <= 1024`

### Limitation for number of thread blocks

- `x <= 2^32 - 1`, `y <= 65536`, `z <= 65536`

## `threadIdx`

- `threadIdx`는 block 내에서 thread의 index를 나타낸다.

```
threads:      |A B C D E F G H|
threadIdx.x:   0 1 2 3 4 5 6 7
threadIdx.y:   0 0 0 0 0 0 0 0
threadIdx.z:   0 0 0 0 0 0 0 0


threads:      |A B C D| |E F G H|
threadIdx.x:   0 1 2 3   0 1 2 3
threadIdx.y:   0 0 0 0   0 0 0 0
threadIdx.z:   0 0 0 0   0 0 0 0


threads:      |P ? Q ?| |? R ? S|

              |T ? U ?| |V ? ? W|

threads:       P Q R S T U V W
threadIdx.x:   0 2 1 3 0 2 0 3
threadIdx.y:   0 0 0 0 0 0 0 0


threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

threads:       X Y P Q R S T U
threadIdx.x:   1 1 0 2 0 3 1 2
threadIdx.y:   0 1 0 1 0 1 0 1
```

다음은 `threadIdx`를 이용한 간단한 예제이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void print_threadIds() {
    printf("threadIdx.x: %d, threadIdx.y: %d, threadIdx.z: %d\n",
        threadIdx.x, threadIdx.y, threadIdx.z);
}

int main() {
    int nx, ny;
    nx = 16;
    ny = 16;

    dim3 block(8, 8);
    dim3 grid(nx / block.x, ny / block.y);

    print_threadIds<< <grid, block >> > ();
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
threadIdx.x: 0, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 1, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 2, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 3, threadIdx.y: 0, threadIdx.z: 0
threadIdx.x: 4, threadIdx.y: 0, threadIdx.z: 0
...
threadIdx.x: 3, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 4, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 5, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 6, threadIdx.y: 7, threadIdx.z: 0
threadIdx.x: 7, threadIdx.y: 7, threadIdx.z: 0
```

## `blockIdx`

CUDA runtime inialize `blockIdx` variable for each thread depending on the coordinates of the belonging thread block in the grid.

`blockIdx`는 `dim3` 타입이다.

```
threads:      |A B C D| |E F G H|
blockIdx.x:    0 0 0 0   1 1 1 1
blockIdx.y:    0 0 0 0   0 0 0 0
blockIdx.z:    0 0 0 0   0 0 0 0


threads:      |P ? Q ?| |? R ? S|

              |T ? U ?| |V ? ? W|

threads:       P Q R S T U V W
blockIdx.x:    0 0 1 1 0 0 1 1
blockIdx.y:    0 0 0 0 1 1 1 1
blockIdx.z:    0 0 0 0 0 0 0 0

threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

threads:       X Y P Q R S T U
blockIdx.x:    0 0 1 1 0 0 1 1
blockIdx.y:    0 0 0 0 1 1 1 1
blockIdx.z:    0 0 0 0 0 0 0 0
```

## `blockDim`

`blockDim`은 thread block의 dimension을 나타낸다. 모든 block은 같은 dimension을 가진다.

```
threads:      |? X ? ?| |P ? ? ?|
              |? Y ? ?| |? ? Q ?|

              |R ? ? ?| |? T ? ?|
              |? ? ? S| |U ? ? ?|

blockDim.x = 4, blockDim.y = 2
```

## `gridDim`

`gridDim`은 grid의 각 dimension의 thread block의 수를 나타낸다.

```
threads:      |? X ? ?| |P ? ? ?| |? ? ? ?|
              |? Y ? ?| |? ? Q ?| |? ? ? ?|

              |R ? ? ?| |? T ? ?| |? ? ? ?|
              |? ? ? S| |U ? ? ?| |? ? ? ?|

gridDim.x = 3, gridDim.y = 2
```

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void print_threadIds() {
    printf("blockIdx.x: %d, blockIdx.y: %d, blockIdx.z: %d, blockDim.x: %d, blockDim.y: %d, blockDim.z: %d, gridDim.x: %d, gridDim.y: %d\n",
        blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z, gridDim.x, gridDim.y);

}

int main() {
    int nx, ny;
    nx = 16;
    ny = 16;

    dim3 block(8, 8);
    dim3 grid(nx / block.x, ny / block.y);

    print_threadIds<< <grid, block >> > ();
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 1, blockIdx.y: 1, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
...
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
blockIdx.x: 0, blockIdx.y: 0, blockIdx.z: 0, blockDim.x: 8, blockDim.y: 8, blockDim.z: 1, gridDim.x: 2, gridDim.y: 2
```

`blockDim`과 `gridDim`은 모든 block에서 동일한 것을 확인할 수 있다.

## Unique index calculation

thread에서 index를 기반으로 데이터에 접근하는 예시이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_idx_calc_threadIdx(int* input) {
    int tid = threadIdx.x;
    printf("threadIdx: %d, value: %d\n", tid, input[tid]);
}

int main() {
    int array_size = 8;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33 };

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(8);
    dim3 grid(1);

    unique_idx_calc_threadIdx << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33

threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
threadIdx: 4, value: 65
threadIdx: 5, value: 12
threadIdx: 6, value: 1
threadIdx: 7, value: 33
```

이번엔 블록을 2개로 늘려보자.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_idx_calc_threadIdx(int* input) {
    int tid = threadIdx.x;
    printf("threadIdx: %d, value: %d\n", tid, input[tid]);
}

int main() {
    int array_size = 8;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33 };

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(2);

    unique_idx_calc_threadIdx << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33

threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
threadIdx: 0, value: 23
threadIdx: 1, value: 9
threadIdx: 2, value: 4
threadIdx: 3, value: 53
```

동일한 value가 두 번 출력되는 것을 확인할 수 있다.

```
threads:      |A B C D| |E F G H| |I J K L| |M N O P|
tid:           0 1 2 3   0 1 2 3   0 1 2 3   0 1 2 3

gid:           0 1 2 3   4 5 6 7   8 9 1 1   1 1 1 1
                                       0 1   2 3 4 5

gid = tid + offset
gid = tid + blockIdx.x * blockDim.x
```

`gid`를 이용하여 data에 접근하도록 만들자.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation(int* input) {
	int tid = threadIdx.x;
	int offset = blockIdx.x * blockDim.x;
	int gid = tid + offset;
	printf("blockIdx.x: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
		printf("%d ", h_data[i]);
	}
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(4);

    unique_gid_calculation << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 3, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 3, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 3, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 3, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 2, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 2, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 2, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 2, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, threadIdx.x: 3, gid: 3, value: 53
```

## Unique index calculation for 2D grid

1D는 다음과 같이 계산할 수 있었다.

```cpp
index = blockIdx.x * blockDim.x + threadIdx.x;
```

이는 `x` dimension만 고려한 것이다. `grid`를 `grid(2, 2)`로 변경하면 잘못된 결과가 나온다.

다음과 같이 수정이 필요하다.

```cpp
gid = gridDim.x * blockDim.x * blockIdx.y  // Row offset
    + blockDim.x * blockIdx.x              // Block offset
    + threadIdx.x;
```

다음은 전체 소스코드이다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation(int* input) {
  int tid = threadIdx.x;
  int block_offset = blockIdx.x * blockDim.x;
  int row_offset = gridDim.x * blockDim.x * blockIdx.y;
  int gid = row_offset + block_offset + tid;
  printf("blockIdx.x: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
      printf("%d ", h_data[i]);
    }
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(4);
    dim3 grid(2, 2);

    unique_gid_calculation << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 1, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 1, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 1, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 1, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 0, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 0, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 0, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 0, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, threadIdx.x: 3, gid: 3, value: 53
```

앞의 예제에서는 각 block이 1D였다. 이번에는 block이 2D인 경우를 생각해보자.

```
------------------> X
. | 0  1| | 4  5|
. | 2  3| | 6  7|
.
. | 8  9| |12 13|
. |10 11| |14 15|
Y
```

이 경우 `tid`가 2D로 변경되어야 한다. `block_offset`과 `row_offset`도 block size를 고려하여 변경되어야 한다.

```cpp
tid = threadIdx.y * blockDim.x + threadIdx.x;

block_offset = number_of_threads_in_a_block * blockIdx.x;
block_offset = (blockDim.x * blockDim.y) * blockIdx.x;

row_offset = number_of_threads_in_a_row * blockIdx.y;
row_offset = (blockDim.x * blockDim.y * gridDim.x) * blockIdx.y;
```

소스 코드는 다음과 같다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>

__global__ void unique_gid_calculation_2d_2d(int* input) {
    int tid = blockDim.x * threadIdx.y + threadIdx.x;

    int num_threads_in_a_block = blockDim.x * blockDim.y;
    int block_offset = num_threads_in_a_block * blockIdx.x;

    int num_threads_in_a_row = num_threads_in_a_block * gridDim.x;
    int row_offset = num_threads_in_a_row * blockIdx.y;

    int gid = row_offset + block_offset + tid;
    printf("blockIdx.x: %d, blockIdx.y: %d, threadIdx.x: %d, gid: %d, value: %d\n", 
        blockIdx.x, blockIdx.y, tid, gid, input[gid]);
}

int main() {
    int array_size = 16;
    int array_byte_size = sizeof(int) * array_size;
    int h_data[] = { 23, 9, 4, 53, 65, 12, 1, 33, 54, 90, 43, 2, 44, 77, 65, 36};

    for (int i = 0; i < array_size; i++) {
        printf("%d ", h_data[i]);
    }
    printf("\n\n");
    int* d_data;
    cudaMalloc((void**)&d_data, array_byte_size);
    cudaMemcpy(d_data, h_data, array_byte_size, cudaMemcpyHostToDevice);

    dim3 block(2, 2);
    dim3 grid(2, 2);

    unique_gid_calculation_2d_2d << <grid, block >> > (d_data);
    cudaDeviceSynchronize();
    cudaDeviceReset();
    return 0;
}
```

```
23 9 4 53 65 12 1 33 54 90 43 2 44 77 65 36

blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 0, gid: 12, value: 44
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 1, gid: 13, value: 77
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 2, gid: 14, value: 65
blockIdx.x: 1, blockIdx.y: 1, threadIdx.x: 3, gid: 15, value: 36
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 0, gid: 8, value: 54
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 1, gid: 9, value: 90
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 2, gid: 10, value: 43
blockIdx.x: 0, blockIdx.y: 1, threadIdx.x: 3, gid: 11, value: 2
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 0, gid: 4, value: 65
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 1, gid: 5, value: 12
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 2, gid: 6, value: 1
blockIdx.x: 1, blockIdx.y: 0, threadIdx.x: 3, gid: 7, value: 33
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 0, gid: 0, value: 23
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 1, gid: 1, value: 9
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 2, gid: 2, value: 4
blockIdx.x: 0, blockIdx.y: 0, threadIdx.x: 3, gid: 3, value: 53
```

## Memory transfer between host and device

![Memory transfer]({{site.baseurl}}/assets/images/2024-05-30-memory-transfer.drawio.svg){: .align-center}

Host와 Device 사이의 데이터 전달이 필요하다.

```cpp
cudaMemCpy(destination_ptr, source_ptr, size_in_byte, direction);

/* Direction
  - Host -> Device  : cudaMemcpyHostToDevice
  - Device -> Host  : cudaMemcpyDeviceToHost
  - Device -> Device: cudaMemcpyDeviceToDevice
*/
```

CUDA device에 메모리를 관리하기 위한 함수들이 있다. 이 함수들은 C의 메모리 관리 함수와 유사하다.

| C | CUDA |
|---|------|
|`malloc`|`cudaMalloc`|
|`memset`|`cudaMemset`|
|`free`|`cudaFree`|

`cudaMalloc`의 첫 번째 인자로 더블 포인터를 주어야 한다. 두 번째 인자로 할당할 메모리의 크기를 전달한다.

```cpp
cudaMalloc((void**)&d_input, byte_size);
```

`cudaMemcpy`로 데이터를 Device Memory로 복사하자.

```cpp
cudaMemcpy(d_input, h_input, byte_size, cudaMemcpyHostToDevice);
```

전체 코드는 다음과 같다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <stdlib.h>
#include <cstring>
#include <time.h>

__global__ void mem_trs_test(int* input) {
    int gid = blockIdx.x * blockDim.x + threadIdx.x;
    printf("tid: %d, gid: %d, value: %d\n", threadIdx.x, gid, input[gid]);
}

int main() {
    int size = 128;
    int byte_size = size * sizeof(int);

    int* h_input;
    h_input = (int*)malloc(byte_size);

    time_t t;
    srand((unsigned)time(&t));
    for (int i = 0; i < size; i++) {
      h_input[i] = (int)(rand() & 0xff); // Random values
    }

    int* d_input;
    cudaMalloc((void**)&d_input, byte_size);
    cudaMemcpy(d_input, h_input, byte_size, cudaMemcpyHostToDevice);

    dim3 block(64);
    dim3 grid(2);

    mem_trs_test << <grid, block >> > (d_input);
    cudaDeviceSynchronize();

    // Free the memory
    cudaFree(d_input);
    free(h_input);

    cudaDeviceReset();
    return 0;
}
```

```
tid: 0, gid: 64, value: 43
tid: 1, gid: 65, value: 211
tid: 2, gid: 66, value: 177
tid: 3, gid: 67, value: 68
tid: 4, gid: 68, value: 248
...
tid: 59, gid: 59, value: 76
tid: 60, gid: 60, value: 221
tid: 61, gid: 61, value: 161
tid: 62, gid: 62, value: 98
tid: 63, gid: 63, value: 167
```

**Tip:**: Hello
{: .notice--warning}

하지만 때로는 데이터의 크기와 `grid`, `block`의 크기가 맞지 않을 수 있다. 이 때는 argument를 추가로 전달하여 처리할 수 있다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <stdlib.h>
#include <cstring>
#include <time.h>

__global__ void mem_trs_test(int* input, int size) {
  int gid = blockIdx.x * blockDim.x + threadIdx.x;
  if (gid < size) {
      printf("tid: %d, gid: %d, value: %d\n", threadIdx.x, gid, input[gid]);
  }
}

int main() {
  int size = 150;
  int byte_size = size * sizeof(int);

  int* h_input;
  h_input = (int*)malloc(byte_size);

  time_t t;
  srand((unsigned)time(&t));
  for (int i = 0; i < size; i++) {
    h_input[i] = (int)(rand() & 0xff); // Random values
  }

  int* d_input;
  cudaMalloc((void**)&d_input, byte_size);
  cudaMemcpy(d_input, h_input, byte_size, cudaMemcpyHostToDevice);

  dim3 block(32);
  dim3 grid(5);

  mem_trs_test << <grid, block >> > (d_input, size);
  cudaDeviceSynchronize();

  // Free the memory
  cudaFree(d_input);
  free(h_input);

  cudaDeviceReset();
  return 0;
}
```

`gid`와 `size`를 비교를 통해 invalid한 접근을 방지한다.

## Sum array example with validity check

array `a`와 `b`를 더한 결과를 `c`에 저장하는 프로그램을 만들어보자.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <cstring>

__global__ void sum_array_gpu(int *a, int *b, int *c, int size) {
  int gid = blockIdx.x * blockDim.x + threadIdx.x;
  if (gid < size) {
    c[gid] = a[gid] + b[gid];
  }
}

void sum_array_cpu(int *a, int *b, int *c, int size) {
  for (int i = 0; i < size; i++) {
    c[i] = a[i] + b[i];
  }
}

void compare_arrays(int *a, int *b, int size) {
  for (int i = 0; i < size; i++) {
    if (a[i] != b[i]) {
      printf("Arrays are different\n");
      return;
    }
  }
  printf("Arrays are same\n");
}

int main() {
  int size = 10000;
  int block_size = 128;

  int NO_BYTES = size * sizeof(int);

  // host pointers
  int *h_a, *h_b, *gpu_results, *h_c;
  h_a = (int*)malloc(NO_BYTES);
  h_b = (int*)malloc(NO_BYTES);
  h_c = (int*)malloc(NO_BYTES);
  gpu_results = (int*)malloc(NO_BYTES);

  // initialize host pointers
  time_t t;
  srand((unsigned)time(&t));
  for (int i = 0; i < size; i++) {
    h_a[i] = (int)(rand() & 0xff);
    h_b[i] = (int)(rand() & 0xff);
  }
  sum_array_cpu(h_a, h_b, h_c, size);

  memset(gpu_results, 0, NO_BYTES);

  // device pointers
  int* d_a, * d_b, * d_c;
  cudaMalloc((int**)&d_a, NO_BYTES);
  cudaMalloc((int**)&d_b, NO_BYTES);
  cudaMalloc((int**)&d_c, NO_BYTES);

  // copy data from host to device
  cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);

  // launching the grid
  dim3 block(block_size);
  dim3 grid((size / block.x) + 1);

  sum_array_gpu << <grid, block >> > (d_a, d_b, d_c, size);

  cudaDeviceSynchronize();
  cudaMemcpy(gpu_results, d_c, NO_BYTES, cudaMemcpyDeviceToHost);

  // array comparison
  compare_arrays(gpu_results, h_c, size);

  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);

  free(gpu_results);
  free(h_a);
  free(h_b);

  cudaDeviceReset();
  return 0;
}
```

## Error handling

본 예시들에서는 간단한 코드를 위해 생략한 경우가 많지만, Industry code에서는 error를 관리해야 한다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <cstring>

#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }

inline void gpuAssert(cudaError_t code, const char* file, int line, bool abort = true) {
  if (code != cudaSuccess) {
    fprintf(stderr, "GPUassert: %s %s %d\n", cudaGetErrorString(code), file, line);
    if (abort) exit(code);
  }
}

__global__ void sum_array_gpu(int *a, int *b, int *c, int size) {
  int gid = blockIdx.x * blockDim.x + threadIdx.x;
  if (gid < size) {
    c[gid] = a[gid] + b[gid];
  }
}

void sum_array_cpu(int *a, int *b, int *c, int size) {
  for (int i = 0; i < size; i++) {
    c[i] = a[i] + b[i];
  }
}

void compare_arrays(int *a, int *b, int size) {
  for (int i = 0; i < size; i++) {
    if (a[i] != b[i]) {
      printf("Arrays are different\n");
      return;
    }
  }
  printf("Arrays are same\n");
}

int main() {
  int size = 10000;
  int block_size = 128;
  cudaError error;

  int NO_BYTES = size * sizeof(int);

  // host pointers
  int *h_a, *h_b, *gpu_results, *h_c;
  h_a = (int*)malloc(NO_BYTES);
  h_b = (int*)malloc(NO_BYTES);
  h_c = (int*)malloc(NO_BYTES);
  gpu_results = (int*)malloc(NO_BYTES);

  // initialize host pointers
  time_t t;
  srand((unsigned)time(&t));
  for (int i = 0; i < size; i++) {
    h_a[i] = (int)(rand() & 0xff);
    h_b[i] = (int)(rand() & 0xff);
  }
  sum_array_cpu(h_a, h_b, h_c, size);

  memset(gpu_results, 0, NO_BYTES);

  // device pointers
  int* d_a, * d_b, * d_c;
  error = cudaMalloc((int**)&d_a, NO_BYTES);
  if (error != cudaSuccess) {
    // check for error (method 1)
    fprintf(stderr, "Error: %s \n", cudaGetErrorString(error));
  } 
  // check for error (method 2)
  gpuErrchk(cudaMalloc((int**)&d_b, NO_BYTES));
  gpuErrchk(cudaMalloc((int**)&d_c, NO_BYTES));

  // copy data from host to device
  cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);

  // launching the grid
  dim3 block(block_size);
  dim3 grid((size / block.x) + 1);

  sum_array_gpu << <grid, block >> > (d_a, d_b, d_c, size);

  cudaDeviceSynchronize();
  cudaMemcpy(gpu_results, d_c, NO_BYTES, cudaMemcpyDeviceToHost);

  // array comparison
  compare_arrays(gpu_results, h_c, size);

  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);

  free(gpu_results);
  free(h_a);
  free(h_b);

  cudaDeviceReset();
  return 0;
}
```

## Elapsed time measurement

아래와 같은 코드를 이용하여 memory transfer time, kernel execution time 등을 측정하고 분석할 수 있다.

```cpp
clock_t start = clock();
// WORK LOAD
clock_t end = clock();
double difference = (double)(end - start);
double execution_time = difference / CLOCKS_PER_SEC;
```

대량 연산 수행 시에는 block size, grid size 조합에 따라 큰 성능 차이가 발생할 수 있다.
최적의 성능 조합을 찾기 위해 시간 측정을 이용한 trial and error 방법을 사용해볼 수 있다.

## Device properties

Device의 computing capability에 따라 특성이 달라질 수 있다.
cuda에서는 device의 정보를 확인할 수 있다.

```cpp
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <stdio.h>

void query_device() {
  int deviceCount = 0;
  cudaGetDeviceCount(&deviceCount);

  if (deviceCount == 0) {
    printf("No CUDA support device found");
  }

  int devNo = 0;
  cudaDeviceProp iProp;
  cudaGetDeviceProperties(&iProp, devNo);

  printf("Device %d: %s\n", devNo, iProp.name);
  printf("  Number of multiprocessors:                     %d\n",
    iProp.multiProcessorCount);
  printf("  clock rate :                     %d\n",
    iProp.clockRate);
  printf("  Compute capability       :                     %d.%d\n",
    iProp.major, iProp.minor);
  printf("  Total amount of global memory:                 %4.2f KB\n",
    iProp.totalGlobalMem / 1024.0);
  printf("  Total amount of constant memory:               %4.2f KB\n",
    iProp.totalConstMem / 1024.0);
  printf("  Total amount of shared memory per block:       %4.2f KB\n",
    iProp.sharedMemPerBlock / 1024.0);
  printf("  Total amount of shared memory per MP:          %4.2f KB\n",
    iProp.sharedMemPerMultiprocessor / 1024.0);
  printf("  Total number of registers available per block: %d\n",
    iProp.regsPerBlock);
  printf("  Warp size:                                     %d\n",
    iProp.warpSize);
  printf("  Maximum number of threads per block:           %d\n",
    iProp.maxThreadsPerBlock);
  printf("  Maximum number of threads per multiprocessor:  %d\n",
    iProp.maxThreadsPerMultiProcessor);
  printf("  Maximum number of warps per multiprocessor:    %d\n",
    iProp.maxThreadsPerMultiProcessor / 32);
  printf("  Maximum Grid size                         :    (%d,%d,%d)\n",
    iProp.maxGridSize[0], iProp.maxGridSize[1], iProp.maxGridSize[2]);
  printf("  Maximum block dimension                   :    (%d,%d,%d)\n",
    iProp.maxThreadsDim[0], iProp.maxThreadsDim[1], iProp.maxThreadsDim[2]);
}

int main() {
  query_device();
}
```

```
Device 0: NVIDIA GeForce RTX 4080 SUPER
  Number of multiprocessors:                     80
  clock rate :                     2610000
  Compute capability       :                     8.9
  Total amount of global memory:                 16768384.00 KB
  Total amount of constant memory:               64.00 KB
  Total amount of shared memory per block:       48.00 KB
  Total amount of shared memory per MP:          100.00 KB
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per block:           1024
  Maximum number of threads per multiprocessor:  1536
  Maximum number of warps per multiprocessor:    48
  Maximum Grid size                         :    (2147483647,65535,65535)
  Maximum block dimension                   :    (1024,1024,64)
```