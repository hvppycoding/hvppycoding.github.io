---
title: "Pymoo: Multi-Objective Optimization in Python 논문 리뷰"
excerpt: "Pymoo: Multi-Objective Optimization in Python 논문 리뷰"
date: 2022-03-25 23:00:00 +0900
header:
  overlay_image: /assets/images/unsplash-thomas-t-math.jpg
  overlay_filter: 0.5
  caption: "Photo by [**Thomas T**](https://unsplash.com/@pyssling240) on [**Unsplash**](https://unsplash.com/)"
categories:
  - Optimization
mathjax: "true"
---
**Notice:** [Pymoo: Multi-Objective Optimization in Python](https://ieeexplore.ieee.org/document/9078759) 논문을 분석한 글입니다.
{: .notice--info}

# Pymoo: Multi-Objective Optimization in Python

## Abstract

파이썬은 데이터 사이언스, 머신러닝, 딥러닝을 위한 프로그래밍 언어가 되었다.  
최적화는 이러한 연구 분야에 타고났기 때문에, 이와 관련된 많은 최적화 프레임워크가 생겨났다. 그 중 몇몇은 multiple objective 최적화를 지원하지만, 이해하기 쉬운 툴을 제공하지는 않는다. 이를 해결하기 위해 우리는 multi-objective 최적화 프레임워크인 pymoo를 개발했다. 
multi-objective 최적화 시나리오 예시를 통해 프레임워크 가이드를 제공한다. 또한 pymoo 아키텍처에 대한 개요를 제공하여 각 모듈의 확장 능력을 보여준다. pymoo 프레임워크의 구현은 customizable하고, 알고리즘은 custom operator를 통해 수정/확장 가능하다. 또한 다양한 single, multi-, many-objective 테스트 문제가 제공되며, gradient는 automatic difference를 통해 구해진다(out of the box: 별도의 설치나 구성 없이 사용 가능). 또한 함수의 병렬 수행이나 시각화 기능, multi-criteria에서의 결정 등 실용적인 기능도 제공한다. 
https://pymoo.org에서 pymoo에 관해 더 많은 정보를 얻을 수 있습니다.  

Python has become the programming language of choice for research and industry projects related to data science, machine learning, and deep learning. Since optimization is an inherent part of these research fields, more optimization related frameworks have arisen in the past few years. Only a few of them support optimization of multiple conflicting objectives at a time, but do not provide comprehensive tools for a complete multi-objective optimization task. To address this issue, we have developed pymoo, a multi-objective optimization framework in Python. We provide a guide to getting started with our framework by demonstrating the implementation of an exemplary constrained multi-objective optimization scenario. Moreover, we give a high-level overview of the architecture of pymoo to show its capabilities followed by an explanation of each module and its corresponding  sub-modules. The implementations in our framework are customizable and algorithms can be modifed/extended by supplying custom operators. Moreover, a variety of single, multi- and many-objective test problems are provided and gradients can be retrieved by automatic differentiation out of the box. Also, pymoo addresses practical needs, such as the parallelization of function evaluations, methods to visualize low and high-dimensional spaces, and tools for multi-criteria decision making. For more information about pymoo, readers are encouraged to visit: https://pymoo.org.  
{: .custom-faint }


## I. Introduction

최적화는 많은 공학, 데이터 분석, 딥러닝 등의 많은 연구 분야에서 핵심적인 역할을 한다. 이 분야들은 빠르게 성장 중이며 대규모 데이터 세트에서 인사이트를 얻거나 정확한 예측 모델을 피팅할 때 최적화의 개념이 사용되고 있다. 알고리즘이 매우 많은 데이터를 다루어야할 때 적절한 프로그래밍 언어로 효율적으로 구현하는 것이 중요하다. Python은 사용하기 쉽고 커뮤니티도 활성화되어 있어 최근 몇년 동안 다양한 연구 분야에서 주로 사용되고 있다. Python은 코드 가독성이 뛰어난 high-level, 크로스플랫폼, 인터프리터 언어이다. 많은 고품질의 라이브러리가 있으며 과학 분야의 모든 계산을 할 수 있다. 이러한 특성으로 인해 Python은 많은 산업 프로젝트와 연구에 적합하다.

Optimization plays an essential role in many scientific areas, such as engineering, data analytics, and deep learning. These fields are fast-growing and their concepts are employed for various purposes, for instance gaining insights from a large data  sets or fitting accurate prediction models. Whenever an algorithm has to handle a significantly large amount of data, an efficient implementation in a suitable programming language is important. Python has become the programming language of choice for the above mentioned research areas over the last few years, not only because it is easy to use but also good community support exists. Python is a high-level, cross-platform, and interpreted programming language that focuses on code readability. A large number of high-quality libraries are available and support for any kind of scientific computation is ensured. These characteristics make Python an appropriate tool for many research and industry projects where the investigations can be rather complex.
{: .custom-faint}


모든 연구의 기본 원칙 중 하나는 연구의 재현 가능성을 보장하고 연구에 사용된 자료에 대한 접근을 제공하는 것이 좋다. 컴퓨터 과학에서 이것은 알고리즘의 스케치와 구현이라고 볼 수 있다. 하지만 최적화 알고리즘의 구현은 어려울 수 있고 특히 벤치마킹에 시간이 오래걸릴 수 있다. 다양한 소스 코드나 통합 라이브러리를 사용하면 시간을 절약할 수 있고 밑바닥에서부터 구현할 때의 오류를 제거할 수 있다.

A fundamental principle of research is to ensure reproducibility of studies and to provide access to materials used in the research, whenever possible. In computer science, this translates to a sketch of an algorithm and the implementation itself. However, the implementation of optimization algorithms can be challenging and specifically benchmarking is time-consuming. Having access to either a good collection of different source codes or a comprehensive library is time-saving and avoids an error-prone implementation from scratch.
{: .custom-faint }

Python에서의 multi-objective 최적화를 다루기 위해 우리는 pymoo를 도입했다. 우리 프레임워크의 목표는 최첨단의 최적화 알고리즘을 제공할 뿐만 아니라 최적화 프로세스 자체와 관련된 다양한 측면을 다루는 것이다. 우리는 알고리즘에 대한 테스트 베드로 사용할 수 있는 single, multi-, many-objective 테스트 문제를 구현했으며, 테스트 문제의 objective 및 constraint 값 외에도 자동 미분(automatic differentiation)을 통해 gradient을 구할 수 있다. 그리고 evaluation 병렬화를 통해 벡터화된 연산, 다중 스레드 실행 및 분산 컴퓨팅을 통해 사용할 수 있다. 또한 pymoo는 다중 목표 최적화 알고리즘으로 얻은 결과의 품질을 측정하기 위한 성능 지표 측정 기능을 제공한다. 저차원 및 고차원 데이터의 시각화를 통한 탐색적 분석 도구를 사용할 수 있으며, 다중 기준 의사 결정 방법은 최적 솔루션 세트로부터 선호되는 단일 최적 솔루션 선택할 수 있도록 한다.

To address this need for multi-objective optimization in Python, we introduce pymoo. The goal of our framework is not only to provide state of the art optimization algorithms, but also to cover different aspects related to the optimization process itself. We have implemented single, multi and many-objective test problems which can be used as a test-bed for algorithms. In addition to the objective and constraint values of test problems, gradient information can be retrieved through automatic differentiation. Moreover, a parallelized evaluation of solutions can be implemented through vectorized computations, multi-threaded execution, and distributed computing. Further, pymoo provides implementations of performance indicators to measure the quality of results obtained by a multi-objective optimization algorithm. Tools for an explorative analysis through visualization of lower and higher-dimensional data are available and multi-criteria decision making methods guide the selection of a single solution from a solution set based on preferences.
{: .custom-faint }

우리의 프레임워크는 모듈식 구현을 통해 확장 가능하도록 설계되었다. 예를 들어, 유전자 알고리즘은 초기 샘플링, 짝짓기 선택, 교차, 돌연변이 및 생존 선택과 같은 특정 하위 모듈을 사용하여 플러그 앤 플레이 방식으로 조립된다. 각 하위 모듈은 독립적인 기능을 수행하므로 다양한 하위 모듈 조합을 통해 알고리즘을 변경할 수 있다. 이 개념을 통해 최종 사용자는
맞춤형 구현을 통한 도메인 지식. 예를 들어, 진화 알고리즘에서 도메인 전문가의 지식으로 생성된 초기 샘플링 모듈을 사용하여 첫 세대를 시작할 수 있다.

Our framework is designed to be extendable through of its modular implementation. For instance, a genetic algorithm is assembled in a plug-and-play manner by making use of specific sub-modules, such as initial sampling, mating selection, crossover, mutation and survival selection. Each sub-module takes care of an aspect independently and, therefore, variants of algorithms can be initiated by passing different combinations of sub-modules. This concept allows end-users to incorporate domain knowledge through custom implementations. For example, in an evolutionary algorithm a biased initial sampling module created with the knowledge of domain experts can guide the initial search.
{: .custom-faint }

또한 우리의 프레임워크는 많은 코드 예시 통해 문서화가 되어 있다. 또한 사용자가 프레임워크에 익숙해지고 기능을 시연할 수 있도록 시작 안내서를 제공한다. 예를 들어, 두 가지 제약 조건이 있는 bi-objective 최적화 문제의 최적화 결과를 보여준다. 가이드에서 발췌한 내용이 이 논문에도 사용되었다. 또한 소프트웨어 설명서에서 최적화 문제를 실행하기 위해 각 알고리즘과 소스 코드에 대한 설명을 제공한다. 그리고 테스트 문제 정의를 보이고 적합 그래프를 제공한다. 프레임워크 문서는 Sphinx를 사용하여 작성되었으며 자동 단위 테스트를 통해 모듈의 정확성이 보장된다. 대부분의 알고리즘은 두 번째 저자와 협력하여 개발되었으며 원래 구현에 대해 광범위하게 벤치마킹하였다.

Furthermore, we like to mention that our framework is well-documented with a large number of available codesnippets. We created a starter's guide for users to become familiar with our framework and to demonstrate its capabilities. As an example, it shows the optimization results of a bi-objective optimization problem with two constraints. An extract from the guide will be presented in this paper. Moreover, we provide an explanation of each algorithm and source code to run it on a suitable optimization problem in our software documentation. Additionally, we show a definition of test problems and provide a plot of their fitness landscapes. The framework documentation is built using Sphinx and correctness of modules is ensured by automatic unit testing. Most algorithms have been developed in collaboration with the second author and have been benchmarked extensively against the original implementations.
{: .custom-faint }

본 논문의 나머지 부분에서는 먼저 Python 및 기타 프로그래밍 언어로 된 관련 기존 최적화 프레임워크를 제시한다. 그 다음 섹션 III에서 pymoo를 시작하기 위한 가이드를 제공한다. 이는 제안된 프레임워크의 가장 중요한 단계이다. 섹션 IV에서는 프레임워크 아키텍처와 각각의 모듈(문제, 알고리즘 및 분석과 같은)을 설명합니다. 그런 다음 각 모듈은 섹션 V에서 VII에 걸쳐 별도로 다룰 것이다. 마지막으로 VIII장에서 결론을 제시한다.

In the remainder of this paper, we first present related existing optimization frameworks in Python and in other programming languages. Then, we provide a guide to getting started with pymoo in Section III which covers the most important steps of our proposed framework. In Section IV we illustrate the framework architecture and the corresponding modules, such as problems, algorithms and related analytics. Each of the modules is then discussed separately in Sections V to VII. Finally, concluding remarks are presented in Section VIII.
{: .custom-faint }

## II. Related Works
생략

## III. Getting Started

이 장에서는 pymoo에 대한 초보자 가이드를 제공한다. 최적화 시나리오에서 가장 중요한 단계로, 프레임워크 설치부터 시작하여 최적화 문제 정의, 최적화 수행 순으로 진행된다.

In the following, we provide a starter's guide for pymoo. It covers the most important steps in an optimization scenario starting with the installation of the framework, defining an optimization problem, and the optimization procedure itself.
{: .custom-faint }



### A. Installation
pymoo는 PyPI로부터 아래 커맨드를 통해 설치할 수 있다.

`pip install -U pymoo`

구성 요소들은 Python 혹은 Cython에서 사용할 수 있다. Cython은 개발자가 기존 Python 코드에 추가적인 주석을 달아 이를 C 또는 C++ 프로그래밍 언어로 번역한다. 번역된 파일은 바이너리 실행 파일로 컴파일되며 이를 통해 계산 속도를 증가시킬 수 있다. pymoo를 설치하는 동안 컴파일을 시도하지만 적절한 컴파일러가 없거나 기타 이유로 실패하면 순수 Python 버전이 설치된다. 컴파일은 선택 사항이며 컴파일 없이도 모든 기능을 사용할 수 있다. 컴파일 및 문제 해결에 대한 자세한 내용은 온라인 설치 가이드에서 찾을 수 있다.

Some components are available in Python and additionally in Cython. Cython allows developers to annotate existing Python code which is translated to C or C++ programming languages. The translated files are compiled to a binary executable and can be used to speed up computations. During the installation of pymoo, attempts are made for compilation, however, if unsuccessful due to the lack of a suitable compiler or other reasons, the pure Python version is installed. We would like to emphasize that the compilation is optional and all features are available without it. More detail about the compilation and troubleshooting can be found in our installation guide online.
{: .custom-faint }

### B. Problem Definition

일반적으로 multi-objective 최적화에는 부등식으로 이루어진 제약 조건들과 최적화해야 하는 다수의 목적 함수가 있다. 목표는 모든 제약 조건을 충족하고 모든 목표 값에 대한 가능한 좋은 솔루션 세트(variable vectors)를 찾는 것이다. 일반적인 형식의 문제 정의는 다음과 같다.

In general, multi-objective optimization has several objective functions with subject to inequality and equality constraints to optimize. The goal is to find a set of solutions (variable vectors) that satisfy all constraints and are as good as possible regarding all its objectives values. The problem definition in its general form is given by:
{: .custom-faint }

$$
\begin{align}
 \min\ &f_m (X) && m=1, ..., M,\\
 s.t.\ &g_j(x) \le 0, &&  j=1,...,J,\\
 &h_k(x)=0, &&  k=1,...,K,\\
 &x_i^L \le x_i \le x_i^U, &&  i=1,...,N.\\
\end{align}
$$

위 식은 N개의 변수, M개의 목표, J개의 부등식 및 K개의 동일성 제약 조건이 있는 multi-objective 최적화 문제를 정의한다. 또한, 각 변수 $x_i$에 대해 하한값 및 상한값($x_i^L$, $x_i^U$)도 정의한다. 다음에서는 두 가지 제약 조건이 있는 양방향 최적화 문제를 설명한다.

The formulation above defines a multi-objective optimization problem with N variables,M objectives, J inequality, and K equality constraints. Moreover, for each variable $x_i$, lower and upper variable boundaries ($x_i^L$and $x_i^U$) are also defined. In the following, we illustrate a bi-objective optimization problem with two constraints.
{: .custom-faint }

$$
\begin{align}
\min\ & f_1(x)=(x_1^2+x_2^2),\\
\max\ & f_2(x)=-(x_1-1)^2-x_2^2,\\
s.t.\ & g_1(x)=2(x_1-0.1)(x_1-0.9)\le 0,\\
& g_2(x)=20(x_1-0.4)(x_1-0.6)\ge 0,\\
& -2 \le x_1 \le 2,\\  
& -2 \le x_2 \le 2.\\
\end{align}
$$

문제는 $f_1(x)$를 최소화하고 $f_2(x)$를 최대화하는 두 개의 목적 함수<sup>Objective</sup>($M = 2$)로 구성된다. 문제에서 두 개의 부등식 제약 조건<sup>Constraint</sup>이 존재하며($J = 2$), $g_1(x)$은 같거나 작음 조건을 만족해야 하며, $g_2(x)$는 같거나 큰 조건을 만족해야 한다. 문제는 $[-2, 2]$ 범위에 있는 두 개의 변수($N = 2$), $x_1$ 및 $x_2$에 대해 정의되었다. 문제에 등식 제약 조건은 포함되어 있지 않다($K = 0$). 목적 함수<sup>Objective function</sup>의 등고선 플롯은 Figure 1에 나와 있다. 목적 함수 $f_1(x)$의 등고선은 실선으로 표현되며 $f_2(x)$는 점선으로 표현되었다. 제약 조건 $g_1(x)$와 $g_2(x)$는 $(0.1, 0.9)$, $(0.4, 0.6)$에서 $x_1$ 축과 교차하는 포물선이다. 파레토 최적 집합은 두꺼운 주황색 선으로 표시된다. 두 제약 조건의 조합으로 인해 파레토 집합은 두 부분으로 나뉩니다. 이를 분석하면, 파레토 최적 집합<sup>Pareto-optimal set</sup>은 $$PS = \{ (x_1, x_2) \vert (0.1 \le x_1 \le 0.4) \bigvee (0.6 \le x_1 \le 0.9) \bigwedge x_2 = 0 \} $$이고, 효율 프론트<sup>Efficient-front</sup>는 $f_2 = (\sqrt{f_1}-1)^2$(단, $f_1$가 $[0.01, 0.16]$와 $[0.36, 0.81]$ 범위 내일 때)이다.

It consists of two objectives($M = 2$) where $f_1(x)$ is minimized and $f_2(x)$ maximized. The optimization is with subject to two inequality constraints ($J = 2$) where $g_1(x)$ is formulated as a less-than-equal-to and $g_2(x)$ as a greaterthan-equal-to constraint. The problem is defined with respect to two variables ($N = 2$), $x_1$ and $x_2$, which both are in the range $[-2, 2]$. The problem does not contain any equality constraints ($K = 0$). Contour plots of the objective functions are shown in Figure 1. The contours of the objective function $f_1(x)$ are represented by solid lines and $f_2(x)$ by dashed lines. Constraints $g_1(x)$ and $g_2(x)$ are parabolas which intersect the $x_1$-axis at $(0.1, 0.9)$ and $(0.4, 0.6)$. The Pareto-optimal set is marked by a thick orange line. Through the combination of both constraints the Pareto-set is split into two parts. Analytically, the Pareto-optimal set is given by $$PS = \{ (x_1, x_2) \vert (0.1 \le x_1 \le 0.4) \bigvee (0.6 \le x_1 \le 0.9) \bigwedge x_2 = 0 \}$$ and the efficient-front by $f_2 = (\sqrt{f_1}-1)^2$ where $f_1$ is defined in $[0.01, 0.16]$ and $[0.36, 0.81]$.
{: .custom-faint }

![Figure 1]({{site.baseurl}}/assets/images/2022-03-26-contour-plot.png "Figure 1"){: .align-center}

**Figure 1. Contour plot of the test problem (Equation 2).**
{: .custom-caption }

다음에서는 pymoo를 사용하여 위의 문제식을 구현한 예시이다. 독자가 Python에 익숙하고 벡터 및 행렬 계산을 처리하는 데 사용되는 NumPy에 대한 기본 지식이 있다고 가정하였다.

In the following, we provide an example implementation of the problem formulation above using pymoo. We assume the reader is familiar with Python and has a fundamental knowledge of NumPy which is utilized to deal with vector and matrix computations. 
{: .custom-faint }

pymoo의 모든 모듈에서는 순수 최소화 문제<sup>Minimization problem</sup>만을 고려한다. 최대화 함수에는 $-1$을 곱하여 최소 문제로 변경하여 적용할 수 있다. 따라서 위 문제에서 $f_2(x)$를 최대화하는 대신 $-f_2(x)$를 최소화해야 한다. 또한 모든 제약 조건은 '같거나 작음'<sup>less-than-equal-to</sup> 제약 조건이어야 한다. 그러므로 $\ge$를 $\le$ 관계로 바꾸기 위해 $g_2(x)$식에 $-1$을 곱해야 한다. 추가적으로 각각의 제약 조건에 동일한 가중치를 부여하기 위해 제약 조건을 정규화할 것을 권장한다. $g_1(x)$의 경우 제약 조건의 상수 값은 $2 \cdot (-0.1) \cdot (-0.9) = 0.18$이고 $g_2(x)$의 경우 $20 \cdot (-0.4 ) \cdot(-0.6) = 4.8$이다. $g_1(x)$와 $g_2(x)$를 해당 상수로 나누어 제약 조건을 정규화하였다.

In pymoo, we consider pure minimization problems for optimization in all our modules. However, without loss of generality an objective which is supposed to be maximized, can be multiplied by $-1$ and be minimized. Therefore, we minimize $-f_2(x)$ instead of maximizing $f_2(x)$ in our optimization problem. Furthermore, all constraint functions need to be formulated as a less-than-equal-to constraint. For this reason, $g_2(x)$ needs to be multiplied by $-1$ to flip the $\ge$ to a $\le$ relation. We recommend the normalization of constraints to give equal importance to each of them. For $g_1(x)$, the constant 'resource' value of the constraint is $2 \cdot (-0.1) \cdot (-0.9) = 0.18$ and for $g_2(x)$ it is $20 \cdot (-0.4) \cdot (-0.6) = 4.8$, respectively. We achieve normalization of constraints by dividing $g_1(x)$ and $g_2(x)$ by the corresponding constant.
{: .custom-faint }

최종적으로 pymoo를 사용하여 최적화할 최적화 문제는 다음과 같이 정의된다:

Finally, the optimization problem to be optimized using pymoo is defined by:
{: .custom-faint }

$$
\begin{aligned} 
  \min\ & f_1(x)=(x_1^2+x_2^2),\\
  \min\ & f_2(x)=(x_1-1)^2+x_2^2,\\
  s.t.\ & g_1(x)=2(x_1-0.1)(x_1-0.9)/0.18\le 0,\\
  & g_2(x)=-20(x_1-0.4)(x_1-0.6)/4.8\le 0,\\
  & -2 \le x_1 \le 2,\\
  & -2 \le x_2 \le 2.\\
\end{aligned}
$$

도출된 문제 식을 Python으로 구현하였다. pymoo의 각 최적화 문제는 `Problem` 클래스를 상속해야한다. 먼저 `super()` 함수를 호출하여 변수<sup>variable</sup>의 수(`n_var`), 목표<sup>objective</sup>(`n_obj`) 및 제약 조건<sup>constraints</sup>(`n_constr`)과 같은 문제 속성을 초기화한다. 또한 하위 경계<sup>lower variables boundary</sup>(`xl`) 및 상위 변수 경계<sup>upper variables boundary</sup>(`xu`)는 NumPy 배열로 나타낸다. 또한 평가 함수 `_evaluate`를 오버라이드해야 한다. `_evaluate` 메소드는 n개의 행과 m개의 열이 있는 2차원 NumPy 배열 `x`를 input으로 사용한다. 각 행은 개별 변수값을 나타내고 각 열은 각각의 최적화 변수를 나타낸다. 필요한 계산을 수행한 후 objective 값은 `F` 키를 사용하여 Dictionary `out`에 추가하고 `G` 키를 사용하여 제약 조건을 추가한다.

Next, the derived problem formulation is implemented in Python. Each optimization problem in pymoo has to inherit from the `Problem` class. First, by calling the `super()` function the problem properties such as the number of variables (`n_var`), objectives (`n_obj`) and constraints (`n_constr`) are initialized. Furthermore, lower (`xl`) and upper variables boundaries (`xu`) are supplied as a NumPy array. Additionally, the evaluation function `_evaluate` needs to be overwritten from the superclass. The method takes a two-dimensional NumPy array `x` with n rows and m columns as an input. Each row represents an individual and each column an optimization variable. After doing the necessary calculations, the objective values are added to the dictionary `out` with the key `F` and the constraints with key `G`.
{: .custom-faint }

위에서 언급했듯이 pymoo는 대부분의 계산에 NumPy를 사용한다. 자동 미분<sup>autograd</sup>을 통해 그라디언트를 계산할 수 있도록 Autograd라고 하는 NumPy 래퍼를 사용한다. 이는 문제 정의 시 필수 사항은 아니다.

As mentioned above, pymoo utilizes NumPy for most of its computations. To be able to retrieve gradients through automatic differentiation we are using a wrapper around NumPy called Autograd. Note that this is not obligatory for a problem definition.
{: .custom-faint }

### C. Algorithm Initialization

다음으로 문제를 최적화하기 위해 메서드를 초기화해야 한다. pymoo에서는 최적화를 위해 알고리즘 객체를 생성해야 한다. 각 알고리즘에 대해 API 문서를 참고할 수 있으며 서로 다른 파라미터를 사용하여 알고리즘을 플러그-앤-플레이 방식으로 사용자가 쉽게 정의할 수 있다. 일반적으로 최적화 문제에 적합한 알고리즘을 선택하는 것부터 쉬운 과정이 아니다. 문제의 특성을 미리 알고있다면 연산자<sup>operator</sup>를 커스터마이즈하여 사용하는 것이 좋다. 우리의 경우 최적화 문제가 다소 단순하지만 두 개의 목적과 두 개의 제약이 있다는 점을 고려해야 한다. 그래서 우리는 NSGA-II의 기본 구성을 약간 수정하여 사용하기로 했다. 우리는 인구 크기<sup>population</sup>를 40으로 선택했지만 동일한 수의 자손<sup>offspring</sup>을 생성하는 대신 각 세대<sup>generation</sup>에 10개만 생성하도록 하였다. 이것은 NSGA-II의 정상 상태 변형<sup>steady-state variant</sup>이며 로컬 Pareto-front와 같은 문제 없이 다소 간단한 최적화 문제에 대해 잘 수렴할 확률이 높아진다. 더욱이, 교미<sup>mating</sup>가 기존 개체군과 다른 자손을 생산하도록 변수 벡터 확인하여 중복 검사를 하도록 하였다. 커스터마이즈 가능한 부분들을 보이기 위해 다른 연산자들도 아래 코드에 나타냈다. NSGA-II의 생성자는 주어진 파라미터를 사용하여 호출되고 초기화된 알고리즘 객체를 반환한다.

Next, we need to initialize a method to optimize the problem. In pymoo, an algorithm object needs to be created for optimization. For each of the algorithms an API documentation is available and through supplying different parameters, algorithms can be customized in a plug-and-play manner. In general, the choice of a suitable algorithm for optimization problems is a challenge itself. Whenever problem characteristics are known beforehand we recommended using those through customized operators. However, in our case the optimization problem is rather simple, but the aspect of having two objectives and two constraints should be considered. For this reason, we decided to use NSGA-II with its default configuration with minor modifications. We chose a population size of 40, but instead of generating the same number of offsprings, we create only 10 in each generation. This is a steady-state variant of NSGA-II and it is likely to improve the convergence property for rather simple optimization problems without much difficulties, such as the existence of local Pareto-fronts. Moreover, we enable a duplicate check which makes sure that the mating produces offsprings which are different with respect to themselves and also from the existing population regarding their variable vectors. To illustrate the customization aspect, we listed the other unmodified default operators in the code-snippet below. The constructor of NSGA2 is called with the supplied parameters and returns an initialized algorithm object.
{: .custom-faint}

### D. Optimization

이제 초기화된 알고리즘 개체를 사용하여 정의된 문제를 최적화할 수 있다. `problem`과 `algorithm` 인스턴스를 매개변수로 하는 `minimize` 함수를 호출한다. 추가적으로 우리는 $40 + 40 \times 10 = 440$회 함수 평가<sup>function evaluation</sup>를 수행하도록 알고리즘을 종료 기준을 40세대로 설정하였다. 또한, 재현성을 보장하기 위해 랜덤 시드를 정의하였고, 각 세대에 대한 출력을 볼 수 있도록 verbose 플래그를 설정하였다.

Next, we use the initialized algorithm object to optimize the defined problem. Therefore, the `minimize` function with both instances `problem` and `algorithm` as parameters is called. Moreover, we supply the termination criterion of running the algorithm for 40 generations which will result in $40 + 40 \times 10 = 440$ function evaluations. In addition, we define a random seed to ensure reproducibility and enable the verbose flag to see printouts for each generation.
{: .custom-faint }

이 메서드는 알고리즘에 의해 찾아진 non-dominated set 솔루션을 담고있는 `Result` 객체를 리턴한다.

The method returns a `Result` object which contains the non-dominated set of solutions found by the algorithm.
{: .custom-faint }

![Figure 2]({{site.baseurl}}/assets/images/2022-03-26-optimization-result.png "Figure 2"){: .align-center}

**Figure 2. Result of the getting started optimization.**
{: .custom-caption }

최적화 결과는 Figure 2에 나와 있으며, 여기서 Figure 2a에서 design space, Figure 2b에 objective space을 나타내었다. 실선은 분석을 통해 도출된 Pareto set와 Pareto front이며, 동그라미 마커들은 알고리즘에서 솔루션을 나타낸다. 알고리즘이 수렴 가능하였고 거의 최적의 솔루션 세트를 얻은 것을 확인할 수 있다. 추가적인 후처리 단계와 최적화 과정의 기타 요소들에 대한 세부 내용은 본 논문 혹은 소프트웨어 설명서에서 확인할 수 있다.

The optimization results are illustrated in Figure 2 where the design space is shown in Figure 2a and in the objective space in Figure 2b. The solid line represents the analytically derived Pareto set and front in the corresponding space and the circles solutions found by the algorithm. It can be observed that the algorithm was able to converge and a set of nearly-optimal solutions was obtained. Some additional post-processing steps and more details about other aspects of the optimization procedure can be found in the remainder of this paper and in our software documentation.
{: .custom-faint }

스타터 가이드는 설치부터 최적화 문제 해결까지의 단계를 보여주었다. 제약 조건이 있는 이중 목표 문제 해결을 통해 최적화 시나리오의 기본 과정을 보였다.

The starters guide showed the steps starting from the installation up to solving an optimization problem. The investigation of a constrained bi-objective problem demonstrated the basic procedure in an optimization scenario.
{: .custom-faint }

## IV. Architecture

소프트웨어 아키텍처는 소스 코드를 체계적으로 유지하기 위해 중요한 요소이다. 한편으로는 개발자와 사용자가 구현된 클래스들을 대략적으로 파악하는 데 도움이 되며, 다른 한편으로는 신규 모듈 추가를 통한 유연성/확장성을 가능케 한다. Figure 3은 pymoo의 아키텍처를 나타낸 것이다. 첫 추상화 단계는 최적화 문제, 알고리즘, 분석 기능으로 구성된다. 각 모듈은 더 세부적으로 분류될 수 있으며 여러 하위 모듈로 구성된다.

Software architecture is fundamentally important to keep source code organized. On the one hand, it helps developers and users to get an overview of existing classes, and on the other hand, it allows flexibility and extendibility by adding new modules. Figure 3 visualizes the architecture of pymoo. The first level of abstraction consists of the optimization problems, algorithms and analytics. Each of the modules can be categorized into more detail and consists of multiple submodules. 
{: .custom-faint }

![Figure 3]({{site.baseurl}}/assets/images/2022-03-26-architecture-of-pymoo.png "Figure 3"){: .align-center}

**Figure 3. Architecture of pymoo.**
{: .custom-caption }

(i) **문제**: 우리 프레임워크의 최적화 문제는 single, multi 및 many-object 문제로 분류된다. 자동 미분<sup>Automatic differentiation</sup>을 통해 그라디언트를 구할 수 있으며 다양한 기술을 통해 병렬화할 수 있다.

(i) **Problems**: Optimization problems in our framework are categorized into single, multi, and many-objective test problems. Gradients are available through automatic differentiation and parallelization can be implemented by using a variety of techniques.
{: .custom-faint }

(ii) **최적화**: 대부분의 알고리즘은 진화 연산<sup>evolutionary computations</sup>을 기반으로 하기 때문에 샘플링, 짝짓기 선택, 교차 및 돌연변이와 같은 연산자를 선택하거나 구현해야 한다. 또한 실제로 많은 문제에는 하나 이상의 제약 조건이 있으므로 이를 처리하는 방법론도 포함되어야 한다. 일부 알고리즘은 다중 목표 문제를 여러 단일 목표 문제로 분할하는 분해를 기반으로 한다. 또한 알고리즘을 사용하여 문제를 해결할 때 종료 기준은 알고리즘 구현에 의해 명시적으로 또는 암시적으로 정의되어야 한다.

(ii) **Optimization**: Since most of the algorithms are based on evolutionary computations, operators such as sampling, mating selection, crossover and mutation have to be chosen or implemented. Furthermore, because many problems in practice have one or more constraints, a methodology for handling those must be incorporated. Some algorithms are based on decomposition which splits the multi-objective problem into many single-objective problems. Moreover, when the algorithm is used to solve the problem, a termination criterion must be defined either explicitly or implicitly by the implementation of the algorithm.
{: .custom-faint }

(iii) **분석**: 최적화 수행 중일 때 혹은 최적화 완료 후 분석 기능을 통해 데이터에 대한 이해를 도울 수 있다. 첫번째로, 시각화를 통해 직관적으로 디자인 공간, 목표 공간 또는 기타 지표를 분석할 수 있다. 또한, Pareto-optimal 집합의 수렴 및 발산 정도를 측정하기 위해 성능 지표를 사용할 수 있다. 실수 매개변수 문제의 경우 최근에 제안된 이론적인 KKT 근접 메트릭 계산 절차<sup>theoretical KKT proximity metric computation procedure</sup>가 pymoo에 포함되어 정확한 위치를 알지 못함에도 실제 Pareto-optimal front에 대한 솔루션의 근접도를 계산할 수 있다. 목표 공간에서 관심 영역에 가까운 지점을 찾거나 절충 솔루션을 통해 의사 결정을 돕는다. 이는 최적화 실행 중에 또는 사후 분석으로 적용할 수 있다.

(iii) **Analytics**: During and after an optimization run analytics support the understanding of data. First, intuitively the design space, objective space, or other metrics can be explored through visualization. Moreover, to measure the convergence and/or diversity of a Pareto-optimal set performance indicators can be used. For real-parameter problems, recently proposed theoretical KKT proximity metric computation procedure is included in pymoo to compute the proximity of a solution to the true Pareto-optimal front, despite not knowing its exact location. To support the decision making process either through finding points close to the area of interest in the objective space or high trade-off solutions. This can be applied either during an optimization run to mimic interactive optimization or as a post analysis.
{: .custom-faint }

본 논문의 나머지 부분에서는 각각의 모듈에 대해 자세히 다룰 것이다.

In the remainder of the paper, we will discuss each of the modules mentioned in more detail.
{: .custom-faint }

## V. Problems

연구자들은 일반적으로 다양한 테스트 문제에서 알고리즘의 성능을 평가한다. '모든 최적화 문제에 적용할 수 있는 최상의 알고리즘'이란 것은 존재하지 않는다는 것을 알고 있기 때문에 이런 성능 평가는 각각의 알고리즘에 적합한 문제 종류를 식별하는 데 도움이 된다. 따라서 다양한 수의 변수, 목표, 제약 조건과 복잡성을 가진 테스트 문제 set는 알고리즘 개발 시 유용하다. 또한, 다중 목표 관점에서는, 다양한 Pareto-front 모양 또는 다양한 최적 변수 밀도를 가진 테스트 문제가 관심 대상이다.

It is common practice for researchers to evaluate the performance of algorithms on a variety of test problems. Since we know no single-best algorithm for all arbitrary optimization problems exist, this helps to identify problem classes where the algorithm is suitable. Therefore, a collection of test problems with different numbers of variables, objectives or constraints and alternating complexity becomes handy for algorithm development. Moreover, in a multi-objective context, test problems with different Pareto-front shapes or varying variable density close to the optimal region are of interest.
{: .custom-faint }

### A. Implementations

우리의 프레임워크에서 Objective 수에 따라 단일 목표<sup>single-objective</sup>(1개 목표), 다중 목표<sup>multi-objective</sup>(2~3개 목표) 및 다수 목표<sup>many-objective</sup>(4개 이상의 목표) 문제로 분류한다. pymoo에 구현된 테스트 문제들은 Table 2에 나타나있다. 각 문제에 대해 변수, 목표 및 제약 조건의 수를 확인 할 수 있다. 테스트 문제의 파라미터를 변경 가능한 경우 (s) 표시를 붙였다. 문제 파라미터를 변경 가능하지만 기존에 제안된 값이 존재하는 경우 괄호 표시로 이를 나타내었다. 해당 카테고리가 문제에 적용되지 않는 경우, 예를 들어 테스트 문제가 여러 함수로 구성된 그룹일 경우 (·)로 표시했다.

In our framework, we categorize test problems regarding the number of objectives: single-objective (1 objective), multi-objective (2 or 3 objectives) and many-objective (more than 3 objectives). Test problems implemented in pymoo are listed in Table 2. For each problem the number of variables, objectives, and constraints are indicated. If the test problem is scalable to any of the parameters, we label the problem with (s). If the problem is scalable, but a default number was original proposed we indicate that with surrounding brackets. In case the category does not apply, for example because we refer to a test problem family with several functions, we use (·).
{: .custom-faint }

![Table 2]({{site.baseurl}}/assets/images/2022-03-26-test-problems.png "Table 2"){: .align-center}
**Table 2. Multi-objective optimization test problems.**
{: .custom-caption }

pymoo의 구현에서는 각 문제에서 반환하는 값을 유저가 설정할 수 있도록 한다. 구현의 관점에서 보면, `Problem` 인스턴스의 `evaluate` 함수는 반환되어야하는 값의 유형을 담고 있는 `return_value_of` 리스트가 있다. 기본적으로 목표 함수 값 "`F`"과 제약 조건이 있는 경우 제약 조건 위반<sup>constraint violation</sup> "`CV`"가 포함된다. 제약 조건 함수 값은 "`G`"를 추가하여 따로 반환할 수 있다. 이를 통해 개발자는 각자의 메서드에 필요한 값을 유연하게 받을 수 있다.

The implementations in pymoo let end-users define what values of the corresponding problem should be returned. On an implementation level, the `evaluate` function of a `Problem` instance takes a list `return_value_of` which contains the type of values being returned. By default the objective values "`F`" and if the problem has constraints the constraint violation "`CV`" are included. The constraint function values can be returned independently by adding "`G`". This gives developers the flexibility to receive the values that are needed for their methods.
{: .custom-faint }
### B. Gradients

모든 테스트 문제는 Autograd를 사용하여 구현되었다. 따라서 자동 미분이 기본적으로 지원된다. 섹션 III에서 최적화 문제를 정의하는 방법을 보였었다.

All our test problems are implemented using Autograd. Therefore, automatic differentiation is supported out of the box. We have shown in Section III how a new optimization problem is defined.
{: .custom-faint }

그래디언트가 계산되어야 한다면 'return_value_of' 리스트의 해당 값 앞에 "`d`"를 추가해야 한다. 예를 들어 목적 함수 값과 그 그래디언트 값을 요청하려면 `return_value_of = ["F", "dF"]`를 사용하면 된다.

If gradients are desired to be calculated the prefix "`d`" needs to be added to the corresponding value of the `return_value_of` list. For instance to ask for the objective values and its gradients `return_value_of = ["F", "dF"]`.
{: .custom-faint }

앞에서 구현한 문제를 예로 들면, 목적 함수 F의 각 변수에 대한 도함수는 다음과 같다.

Let us consider the problem we have implemented shown in Equation 3. The derivation of the objective functions F with respect to each variable is given by:
{: .custom-faint }

$$
\begin{aligned}
  \nabla F = \begin{bmatrix} 2 x_1 & 2 x_2 \\ 2(x_1 - 1) & 2 x_2 \end{bmatrix}
\end{aligned}
$$

`[0.1, 0.2]`에서의 그래디언트는 다음과 같이 계산할 수 있다.

The gradients at the point `[0.1, 0.2]` are calculated by:
{: .custom-faint }


```python
F, dF = problem.evaluate(np.array([0.1, 0.2]), return_values_of=["F", "dF"])
```

이는 다음과 같은 output을 리턴한다.

returns the following output.
{: .custom-faint }

```python
F = [0.05, 0.85]
dF = [[ 0.2,  0.4],
      [-1.8,  0.4]]
```

이는 계산한 그래디언트 도함수 값과 비교하여 쉽게 검증할 수 있다. 제약 조건 함수의 그래디언트 값은 `return_value_of` 리스트에 "`dG`"를 추가하여 계산할 수 있다.

It can easily be verified that the values are matching with the analytic gradient derivation. The gradients for the constraint functions can be calculated accordingly by adding "`dG`" to the `return_value_of` list.
{: .custom-faint }
### C. Parallelization

평가 함수를 계산할 때 시간이 오래 걸린다면 솔루션 세트를 순차적으로 평가하는 방식이 전체 최적화 과정에서 병목이 될 수 있다. 이러한 이유로 계산을 보다 효율적으로 분산하기 위해 병렬화가 필요할 수 있다. pymoo에서 평가 함수는 알고리즘이 population을 사용하는 경우 솔루션 세트를 입력 받는다. 평가 함수<sup>Evaluation function</sup>가 종료될 때 솔루션 세트에 대한 목적 함수 값이 출력으로 기록되기만 하면 되므로 사용자는 모든 종류의 병렬화를 사용할 수 있다. 우리의 프레임워크에는 병렬화를 구현할 수 있는 몇 가지 기능이 제공된다.

If evaluation functions are computationally expensive, a serialized evaluation of a set of solutions can become the bottleneck of the overall optimization procedure. For this reason, parallelization is desired for an use of existing computational resources more efficiently and distribute long-running calculations. In pymoo, the evaluation function receives a set of solutions if the algorithm is utilizing a population. This empowers the user to implement any kind of parallelization as long as the objective values for all solutions are written as an output when the evaluation function terminates. In our framework, a couple of possibilities to implement parallelization exist:
{: .custom-faint }

(i) 벡터화된 평가<sup>Vectorized Evaluation</sup>: 평가를 병렬화하기 위해 사용되는 일반적인 기술은 각 행이 솔루션을 나타내는 행렬을 사용하는 것이다. 벡터화된 평가는 열 전체를 사용하여 전체 솔루션의 각 변수를 한 번에 다룰 수 있다. 이를 통해 벡터를 사용하여 모든 솔루션의 목적 값을 한 번에 계산할 수 있다. 섹션 III에 있는 예제 문제의 코드 스니펫은 NumPy를 사용한 이러한 구현을 보여주었다. 적절한 하드웨어와 올바르게 설치된 드라이버가 있다면 PyTorch 텐서를 사용하면 GPU에서 계산을 수행하여 약간의 오버헤드만으로 계산을 수행할 수도 있다.

(i) Vectorized Evaluation: A common technique to parallelize evaluations is to use matrices where each row represents a solution. Therefore, a vectorized evaluation refers to a column which includes the variables of all solutions. By using vectors the objective values of all solutions are calculated at once. The code-snippet of the example problem in Section III shows such an implementation using NumPy. To run calculations on a GPU, implementing support for PyTorch tensors can be done with little overhead given suitable hardware and correctly installed drivers.
{: .custom-faint }

(ii) 스레드 루프별 평가: 함수 평가가 독립적으로 수행되어야 하는 경우 for 루프를 사용하여 값을 설정할 수 있다. 기본적으로 평가는 순차 수행되고 병렬로 계산되지 않는다. 평가 함수에 키워드를 제공함으로써 pymoo는 각 평가에 대한 스레드를 생성하고 Python의 기본 스레드 풀 구현을 사용하여 이를 관리하게 할 수 있다. 이 방식은 별개의 설정 없이 사용 가능하며 병렬 스레드 갯수는 설정 가능하다.

(ii) Threaded Loop-wise Evaluation: If the function evaluation should occur independently, a for loop can be used to set the values. By default the evaluation is serialized and no calculations occur in parallel. By providing a keyword to the evaluation function, pymoo spawns a thread for each evaluation and manages those by using the default thread pool implementation in Python. This behaviour can be implemented out of the box and the number of parallel threads can be modified.
{: .custom-faint }

(iii) 분산 평가<sup>Distributed Evaluation</sup>: 평가가 단일 머신으로 제한되지 않아야 하는 경우, 평가 자체를 여러 작업자 또는 전체 클러스터에 배포할 수 있다. 다양한 수준에서 분산 계산을 가능하게 하는 Dask를 사용하는 것이 좋다. 예를 들어, 행렬 연산 자체를 분산하거나 함수 전체를 아웃소싱할 수도 있다. 루프 방식의 평가와 유사하게 각 솔루션은 작업자에게 전송하여 element 단위로 평가할 수 있다.

(iii) Distributed Evaluation: If the evaluation should not be limited to a single machine, the evaluation itself can be distributed to several workers or a whole cluster. We recommend using Dask which enables distributed computations on different levels. For instance, the matrix operation itself can be distributed or a whole function can be outsourced. Similar to the loop wise evaluation each individual can be evaluate element-wise by sending it to a worker.
{: .custom-faint }
## VI. Optimization Module

최적화 모듈은 알고리즘에서 사용할 다양한 종류의 하위 모듈을 제공한다. 그 중 일부는 분해<sup>decomposition</sup> 및 종료 기준<sup>termination criterion</sup>과 같은 일반적인 특성에 속하고 다른 일부는 진화 연산<sup>evolutionary computing</sup>에 관련이 있다. 이러한 모듈을 조합하여 알고리즘이 구성된다.

The optimization module provides different kinds of sub-modules to be used in algorithms. Some of them are more of a generic nature, such as decomposition and termination criterion, and others are more related to evolutionary computing. By assembling those modules together algorithms are built.
{: .custom-faint }
### A. Algorithms

pymoo에서 사용 가능한 알고리즘 구현은 아래 표에 나열되어 있다. 다른 최적화 프레임워크와 비교할 때 알고리즘이 다소 적어 보일 수 있지만 각 알고리즘은 사용자 정의할 수 있으며 파라미터를 통해 변경할 수 있다. 예를 들어, Steady-State NSGA-II를 자손의 수를 1로 설정할 수 있다. 이는 섹션 III에 보인 것처럼 초기화 함수에서 파라미터로 설정할 수 있다. 또한 NSGA-III 또는 MOEAD와 같은 many-objective 알고리즘은 참조 방향<sup>reference direction</sup>을 설정해야 한다는 점을 들고 싶다. 참조 방향은 일반적으로 균일하거나 관심 영역을 향해 편향을 갖는 것이 바람직하다. 우리의 프레임워크는 고정된 수의 포인트에 대한 Das and Dennis method를 제공하며(주로 파티션 수라는 파라미터에 의해 고정됨), 최근 임의의 숫자의 포인트들에 대해 잘 분포된 포인트 세트를 만들어내는 Riesz-Energy 기반 방법론을 사용하여 목표 공간의 선호 영역으로 향하는 편향을 도입할 수 있다.

Available algorithm implementations in pymoo are listed in Table 3. Compared to other optimization frameworks the list of algorithms may look rather short, however, each algorithm is customizable and variants can be initialized with different parameters. For instance, a Steady-State NSGA-II can be initialized by setting the number of offspring to 1. This can be achieved by supplying this as a parameter in the initialization method as shown in Section III. Moreover, it is worth mentioning that many-objective algorithms, such as NSGA-III or MOEAD, require reference directions to be provided. The reference directions are commonly desired to be uniform or to have a bias towards a region of interest. Our framework offers an implementation of the Das and Dennis method for a fixed number of points(fixed with respect to a parameter often referred to as partition number) and a recently proposed Riesz-Energy based method which creates a well-spaced point set for an arbitrary number of points and is capable of introducing a bias towards preferred regions in the objective space.
{: .custom-faint }


| Algorithm |
|-----------|
| GA |
| BRKGA |
| DE |
| Nelder-Mead |
| NSGA-II |
| RNSGA-II |
| NSGA-III |
| UNSGA-III |
| RNSGA-III |
| MOEAD |


### B. Operators

다음과 같은 진화 연산을 사용 가능하다.

The following evolutionary operators are available:
{: .custom-faint }

(i) 샘플링<sup>Sampling</sup>: 초기 모집단은 대부분 샘플링을 기반으로 만들어진다. 때로는 도메인 지식을 기반으로 초기 모집단을 구성할 수도 있고, 일부 솔루션은 이미 평가 완료되어 초기 모집단으로 바로 사용할 수도 있다. 아니면 실수, 정수 또는 이진 변수에 대해 무작위로 샘플링될 수 있다. 또한 Latin-Hypercube 샘플링은 실수 변수에 사용될 수 있다.

(i) Sampling: The initial population is mostly based on sampling. In some cases it is created through domain knowledge and/or some solutions are already evaluated, they can directly be used as an initial population. Otherwise, it can be sampled randomly for real, integer, or binary variables. Additionally, Latin-Hypercube Sampling can be used for real variables.
{: .custom-faint }

(ii) 교차<sup>Crossover</sup>: 다양한 유형의 변수에 대한 다양한 교차 연산자가 구현된다. Figure 4에는 그 중 일부가 나와 있다. Figure 4a부터 4d까지는 두 부모가 관련된 교차에서 정보 교환을 시각화하는 데 도움이 된다. 각 행은 자손<sup>offspring</sup>을 나타내고 각 열은 변수를 나타낸다. 해당 상자는 자손의 값이 첫 번째와 두 번째 부모 중 어느 부모로부터 상속되었는지 여부를 나타냅니다. 1점 및 2점 교차의 경우 변수 시퀀스에 1개 또는 2개의 경계점이 존재함을 관찰할 수 있다. 반대로 UX(Uniform Crossover)에는 명확한 패턴이 없다. 각 변수가 첫 번째 또는 두 번째 부모로부터 무작위로 선택되기 때문이다. HUX(Half Uniform Crossover)의 경우 서로 다른 절반의 변수가 교환된다. 설명을 위해 10가지 부분에 대해 다른 값을 갖는 두 개의 부모를 만들었다. 실수 변수의 경우 Simulated Binary Crossover가 효율적인 교차로 알려져 있다. 이는 이진 인코딩된 변수의 교차를 모방한다. 그림 4e는 부모가 $x_1 = 0.2$ 이고 $x_2 = 0.8$일 때($x_i \in [0, 1]$), $\eta = 0.8$으로 재결합하였을 때 확률 분포를 보여준다. 이와 비슷하게, 정수 변수의 경우 우리는 교차를 적용하기 전에 하한에서 $0.5$를 빼고 상한에 ($0.5 - \epsilon$])를 더한 후 나중에 가까운 정수로 반올림한다(Figure 4f 참조).

(ii) Crossover: Avariety of crossover operators for different type of variables are implemented. In Figure 4 some of them are presented. Figures 4a to 4d help to visualize the information exchange in a crossover with two parents being involved. Each row represents an offspring and each column a variable. The corresponding boxes indicate whether the values of the offspring are inherited from the first or from the second parent. For one and two-point crossovers it can be observed that either one or two cuts in the variable sequence exist. Contrarily, the Uniform Crossover (UX) does not have any clear pattern, because each variable is chosen randomly either from the first or from the second parent. For the Half Uniform Crossover (HUX) half of the variables, which are different, are exchanged. For the purpose of illustration, we have created two parents that have different values in 10 different positions. For real variables, Simulated Binary Crossover is known to be an efficient crossover. It mimics the crossover of binary encoded variables. In Figure 4e the probability distribution when the parents $x_1 = 0.2$ and $x_2 = 0.8$ where $x_i \in [0, 1]$ with $\eta = 0.8$ are recombined is shown. Analogously, in case of integer variables we subtract $0.5$ from the lower and add ($0.5 - \epsilon$]) to the upper bound before applying the crossover and round to the nearest integer afterwards (see Figure 4f).
{: .custom-faint }

![Figure 4]({{site.baseurl}}/assets/images/2022-03-26-crossover-operators.png "Figure 4"){: .align-center}
**Figure 4. Illustration of some crossover operators for different variables types.**
{: .custom-caption }

(iii) 돌연변이<sup>Mutation</sup>: 실수 및 정수 변수의 경우 다항식 돌연변이, 이진 변수의 경우 Bitflip 돌연변이를 사용할 수 있다.

(iii) Mutation: For real and integer variables Polynomial Mutation, and for binary variables Bitflip mutation is provided.
{: .custom-faint }

서로 다른 문제에 대해서 서로 다른 유형의 연산자가 필요하다. 실용적 관점 보았을 때, 문제가 반복적이고 일상적으로 해결되어야 하는 경우 알고리즘의 수렴성을 개선하기 위해 진화 연산자를 커스터마이즈하는 것이 합리적이다. 또한 사용자 정의 변수 타입(예: 객체 트리 또는 혼합 변수)의 경우 사용자 정의 연산자를 쉽게 구현하여 알고리즘 클래스에서 호출될 수 있다. 소프트웨어 문서에 사용자 정의 모듈, 연산자 및 변수 타입에 대한 예시가 포함되어 있다.

Different problems require different type of operators. In practice, if a problem is supposed to be solved repeatedly and routinely, it makes sense to customize the evolutionary operators to improve the convergence of the algorithm. Moreover, for custom variable types, for instance trees or mixed variables, custom operators can be implemented easily and called by algorithm class. Our software documentation contains examples for custom modules, operators and variable types.
{: .custom-faint }
### C. Termination Criterion

모든 알고리즘에 대해 실행을 종료해야 하는 시기를 결정해야 한다. 이는 단순하게는 미리 설정한 횟수만큼의 함수 평가 혹은 반복부터, 시간 경과에 따른 성능 메트릭의 변화 같은 고급 기준을 기반으로 할 수도 있다. 예를 들어, 우리는 변수 공간과 목표 공간의 세대 간 차이를 기반으로 종료 기준을 구현했다. 종료 기준을 보다 강건하게 만들기 위해 마지막 k 세대가 고려된다. 각 솔루션에서 가장 가까운 이웃으로부터 가장 큰 이동이 전세대에 걸쳐 추적되며, 이 값이 특정 임계치 이하일 때 알고리즘이 수렴된 것으로 간주한다. 유사하게, 목표 공간에서의 움직임도 기준으로 사용될 수 있다. 그러나 목표 공간에서 정규화는 더 어려우며 신중하게 다루어야 한다. pymoo에서 multi-objective 문제에 대한 기본 종료 기준은 목표 공간의 경계 지점을 추적하고 경계 지점이 안정화되는 것을 기준으로 한다. 제안된 종료 기준에 대한 자세한 내용은 [47]에서 확인할 수 있다.

For every algorithm it must be determined when it should terminate a run. This can be simply based on a predefined number of function evaluations, iterations, or a more advanced criterion, such as the change of a performance metric over time. For example, we have implemented a termination criterion based on the variable and objective space difference between generations. To make the termination criterion more robust the last k generations are considered. The largest movement from a solution to its closest neighbour is tracked across generation and whenever it is below a certain threshold, the algorithm is considered to have converged. Analogously, the movement in the objective space can also be used. In the objective space, however, normalization is more challenging and has to be addressed carefully. The default termination criterion for multi-objective problems in pymoo keeps track of the boundary points in the objective space and uses them, when they have settled down, for normalization. More details about the proposed termination criterion can be found in [47].
{: .custom-faint }


### D. Decomposition

분해<sup>Decomposition</sup>는 다중 목표<sup>multi-objective</sup> 문제를 다수의 단일 목표<sup>single-objective</sup> 최적화 문제로 변환한다. 이러한 기술은 다중 목표 알고리즘에 포함되어 단일 목표 옵티마이저를 사용하여 동시에 또는 독립적으로 진행할 수 있다. 일부 분해 방법은 p 값이 다른 lp-메트릭을 기반으로 한다. 예를 들어 단순하지만 자주 사용되는 분해 방식은 가중합법(Weighted-Sum Method)($p = 1$)으로, 이는 파레토 프론트의 볼록하지 않은 부분<sup>non-convex part</sup>의 경우 수렴하지 못하는 것으로 알려져 있다. 또한 Tchebysheff method($p = \inf$)은 값을 합산하는 대신 이상적인 지점과 솔루션 간의 최대 차이 값만 고려한다. 유사하게, Achievement Scalarization Function(ASF) 및 수정된 버전인 AASF(Augmented Achievement Scalarization Function)는 모든 차이의 최대값을 사용한다. 또한, 페널티 경계 교차점(Penalty Boundary Intersection)은 기준 방향에 대한 점의 투영 노름<sup>norm of the projection</sup>과 수직 거리의 가중치 합으로 계산됩니다. 정규화는 모든 종류의 분해에 필수적이라는 점을 알아두자. 위에서 언급한 모든 분해 기술은 pymoo에서 구현되어있다.

Decomposition transforms multi-objective problems into many single-objective optimization problems. Such a technique can be either embedded in a multi-objective algorithm and solved simultaneously or independently using a single-objective optimizer. Some decomposition methods are based on the lp-metrics with different p values. For instance, a naive but frequently used decomposition approach is the Weighted-Sum Method ($p = 1$), which is known to be not able to converge to the non-convex part of a Pareto-front. Moreover, instead of summing values, Tchebysheff Method ($p = \inf$) considers only the maximum value of the difference between the ideal point and a solution. Similarly, the Achievement Scalarization Function (ASF) and a modified version Augmented Achievement Scalarization Function (AASF) use the maximum of all differences. Furthermore, Penalty Boundary Intersection (PBI) is calculated by a weighted sum of the norm of the projection of a point onto the reference direction and the perpendicular distance. Also it is worth to note that normalization is essential for any kind of decomposition. All decomposition techniques mentioned above are implemented in pymoo.
{: .custom-faint }
## VII. Analytics

### A. Performance Indicators

단일 목표 최적화 알고리즘의 경우 각 최적화 수행이 단일한 최상의 솔루션을 가지기 때문에 성능에 대한 비교가 간단하다. 그러나 다중 목표 최적화에서 각 실행은 비우세<sup>non-dominated</sup> 솔루션 세트를 반환한다. 솔루션 세트를 비교하기 위해 과거에 다양한 성능 지표가 제안되었다. pymoo에서 가장 일반적으로 사용되는 성능 지표들은 다음과 같다.

For single-objective optimization algorithms the comparison regarding performance is rather simple because each optimization run results in a single best solution. In multi-objective optimization, however, each run returns a non-dominated set of solutions. To compare sets of solutions, various performance indicators have been proposed in the past. In pymoo most commonly used performance indicators are described:
{: .custom-faint }

(i) GD/IGD: Pareto-front PF가 주어지면 알고리즘에서 찾은 비우세 집합 S와 최적값 간의 편차를 측정할 수 있다. 이 원칙에 따라 GD(Generational Distance) 표시기는 S의 각 솔루션에서 PF의 가장 가까운 솔루션까지 목표 공간에서의 평균 유클리드 거리를 계산한다. 이는 S의 수렴도를 측정하지만 Paretofront에서 좋은 다양성에 도달했는지 여부를 나타내지는 않는다. 유사하게, IGD(Inverted Generational Distance) 지표는 PF의 각 솔루션에서 S의 가장 가까운 솔루션까지 목표 공간에서의 평균 유클리드 거리를 측정한다. Paretofront는 전체적으로 성능 메트릭을 최소화하기 위해 S의 솔루션으로 다루어야 한다. 따라서 GD 및 IGD 값이 낮을수록 더 좋은 세트이다. 그러나 IGD는 Pareto compliant가 아닌 것으로 알려져 있다.

(i) GD/IGD: Given the Pareto-front PF the deviation between the non-dominated set S found by the algorithm and the optimum can be measured. Following this principle, Generational Distance (GD) indicator calculates the average Euclidean distance in the objective space from each solution in S to the closest solution in PF. This measures the convergence of S, but does not indicate whether a good diversity on the Paretofront has been reached. Similarly, Inverted Generational Distance (IGD) indicator measures the average Euclidean distance in the objective space from each solution in PF to the closest solution in S. The Paretofront as a whole needs to be covered by solutions from S to minimize the performance metric. Thus, lower the GD and IGD values, the better is the set. However, IGD is known to be not Pareto compliant.
{: .custom-faint }

(ii) GDC/IGDC: GD와 IGD의 변형이 [53]에서 제안되었다. 유클리드 거리는 우세 관계<sup>dominance relation</sup>를 고려한 거리 측정으로 대체된다. 저자는 IGDC가 약한 Pareto compliant임을 보인다.

(ii) GDC/IGDC: A variation of GD and IGD has been proposed in [53]. The Euclidean distance is replaced by a distance measure that takes the dominance relation into account. The authors show that IGDC is weakly Pareto compliant.
{: .custom-faint }

(iii) Hypervolume: 목표 공간의 dominated 부분을 사용하여 비지배적 솔루션의 품질을 측정할 수 있다. 하이퍼볼륨 값이 높을수록 더 좋은 세트이다. Pareto-front 대신에 기준점이 제공되어야 한다. Hypervolume은 Pareto compliant인 것으로 나타났습니다. 성능 메트릭은 높은 차원 공간일수록 계산이 많이 필요하기 때문에 정확한 측정은 다루기 어렵다. 그러나 가까운 시일 내에 몇 가지 제안된 근사 방법을 포함할 계획이다.

(iii) Hypervolume: Moreover, the dominated portion of the objective space can be used to measure the quality of non-dominated solutions. The higher the hypervolume, the better is the set. Instead of the Pareto-front a reference point needs to be provided. It has been shown that Hypervolume is Pareto compliant. Because the performance metric becomes computationally expensive in higher dimensional spaces the exact measure becomes intractable. However, we plan to include some proposed approximation methods in the near future.
{: .custom-faint }

성능 지표는 기존 알고리즘을 비교하는 데 사용된다. 게다가, 새로운 알고리즘의 개발 시 여러가지 지표 평가를 통해 의해 주도될 수 있다.

Performance indicators are used to compare existing algorithms. Moreover, the development of new algorithms can be driven by the goodness of different metrics itself.
{: .custom-faint }
### B. Visualization

중간 단계 또는 최종 결과의 시각화는 불가피하다. 다중 및 다수 목표 최적화에서 목표 공간의 솔루션 간의 trade-off 정보를 쉽게 확인하기 위해 시각화가 중요하다. 목표 공간의 차원에 따라 단일 솔루션 또는 솔루션 세트를 나타내는 데 적합한 플롯 유형이 존재한다. pymoo에 구현된 시각화 기능은 Python Matplotlib의 잘 알려진 플로팅 라이브러리를 래핑하고 있다. Matplotlib 자체에서 제공하는 키워드 인수는 여전히 사용할 수 있어 색상, 두께, 선의 불투명도, 점 또는 기타 모양을 수정할 수 있다. 이를 사용하여 모든 시각화 기능을 커스터마이즈 및 확장할 수 있다.

The visualization of intermediate steps or the final result is inevitable. In multi and many-objective optimization, visualization of the objective space is of interest so that trade-off information among solutions can be easily experienced from the plots. Depending on the dimension of the objective space, different types of plots are suitable to represent a single or a set of solutions. In pymoo the implemented visualizations wrap around the well-known plotting library in Python Matplotlib. Keyword arguments provided by Matplotlib itself are still available which allows to modify for instance the color, thickness, opacity of lines, points or other shapes. Therefore, all visualization techniques are customizable and extendable.
{: .custom-faint }

2개 또는 3개의 목표에 대해 산점도<sup>scatter plots</sup>(Figure 5a 및 5b 참조)는 솔루션 세트에 대한 좋은 직관을 제공할 수 있다. 트레이드오프는 두 점 사이의 거리를 고려하여 판단할 수 있다. 값 간의 비교가 절대값이 아닌 상대값을 기반으로 하도록 각 목표를 정규화하는 것이 바람직할 수도 있다. 쌍별 산점도<sup>Pairwise Scatter Plots</sup>(Figure 5c 참조)는 각 축 쌍을 독립적으로 표시하여 3개 이상의 목표를 시각화한다. 대각선 영역은 해당 목표의 레이블을 표시하는 데 사용된다.

For 2 or 3 objectives, scatter plots (see Figure 5a and 5b) can give a good intuition about the solution set. Trade-offs can be observed by considering the distance between two points. It might be desired to normalize each objective to make sure a comparison between values is based on relative and not absolute values. Pairwise Scatter Plots (see Figure 5c) visualize more than 3 objectives by showing each pair of axes independently. The diagonal is used to label the corresponding objectives.
{: .custom-faint }

또한 고차원 데이터는 Figure 5d와 같이 PCP(Parallel Coordinate Plots)로 설명할 수 있다. 모든 축은 세로로 표시되며 목표를 나타낸다. 각 솔루션은 왼쪽에서 오른쪽 이어진 하나의 선으로 표시됩니다. 선과 축의 교차점은 해당 목표에 대한 솔루션의 값을 나타낸다. 솔루션 비교를 위해 색상과 불투명도를 변경하여 강조할 수 있다.

Also, high-dimensional data can be illustrated by Parallel Coordinate Plots (PCP) as shown in Figure 5d. All axes are plotted vertically and represent an objective. Each solution is illustrated by a line from the left to the right. The intersection of a line and an axis indicate the value of the solution regarding the corresponding objective. For the purpose of comparison solution(s) can be highlighted by varying color and opacity.
{: .custom-faint }

시각화 시 일반적인 관행은 변환 함수를 사용하여 더 높은 차원의 목적 값을 2D 평면에 투영하는 것이다. Radviz(Figure 5e) 플롯은 원 안에 모든 점을 시각화하고 목표 축은 원 주변에 일정하게 배치된다. 최소화 문제와 비지배 솔루션 세트를 고려할 때 축에 매우 가까운 점은 해당 목표에 대한 최악의 솔루션을 나타내지만 하나 또는 많은 다른 목표에서 비교적 좋다. 유사하게, Star Coordinate Plots(Figure 5f)는 목적 공간을 보여줍니다(변환 함수가 원 외부의 솔루션을 허용).

Moreover, a common practice is to project the higher dimensional objective values onto the 2D plane using a transformation function. Radviz (Figure 5e) visualizes all points in a circle and the objective axes are uniformly positioned around on the perimeter. Considering a minimization problem and a set of non-dominated solutions, an extreme point very close to an axis represents the worst solution for that corresponding objective, but is comparably "good" in one or many other objectives. Similarly, Star Coordinate Plots (Figure 5f) illustrate the objective space, except that the transformation function allows solutions outside of the circle.
{: .custom-faint }

히트맵(Figure 5g)은 솔루션의 좋은 정도를 색상을 통해 나타낸다. 각 행은 솔루션을 나타내고 각 열은 변수를 나타낸다. 어떤 색상 맵을 사용할지와 밝은 색상 또는 어두운 색상이 더 나은 솔루션을 나타내는지 또는 더 나쁜 솔루션을 나타내는지 여부에 대한 선택은 최종 사용자에게 남겨둔다. 또한 솔루션은 해당 목표 값에 따라 정렬될 수 있다.

Heatmaps (Figure 5g) are used to represent the goodness of solutions through colors. Each row represents a solution and each column a variable. We leave the choice to the end-user of what color map to use and whether light or dark colors illustrate better or worse solutions. Also, solutions can be sorted lexicographically by their corresponding objective values.
{: .custom-faint }

솔루션 세트를 시각화하는 대신 한 번에 하나의 솔루션을 나타낼 수도 있다. 꽃잎 다이어그램<sup>Petal Diagram</sup>(Figure 5h)은 목표 값이 각 조각의 지름으로 표시되는 파이 다이어그램이다. 색상은 각 조각을 구분하는 데 사용된다. 마지막으로 스파이더 웹 또는 레이더 다이어그램(Figure 5i)은 목표 값을 축의 한 점으로 보여준다. 이상적인 점 및 최하점은 내부 및 외부 다각형으로 표시된다. 정의에 따르면 솔루션은 두 극단 사이에 존재한다. 목적 공간 범위가 다르면 플로팅을 위한 정규화를 진행하여 다이어그램이 대칭이 되게 한다. 2.5차원 PaletteViz 플롯과 같은 3차원 이상의 효율적인 솔루션을 시각화하기 위한 새롭고 새로운 방법이 미래에 구현될 것이다.

Instead of visualizing a set of solutions, one solution can be illustrated at a time. The Petal Diagram (Figure 5h) is a pie diagram where the objective value is represented by each piece's diameter. Colors are used to further distinguish the pieces. Finally, the Spider-Web or Radar Diagram (Figure 5i) shows the objectives values as a point on an axis. The ideal and nadir point  is represented by the inner and outer polygon. By definition, the solution lies in between those two extremes. If the objective space ranges are scaled differently, normalization for the purpose of plotting can be enabled and the diagram becomes symmetric. New and emerging methods for visualizing more than three-dimensional efficient solutions, such as 2.5-dimensional PaletteViz plots, would be implemented in the future.
{: .custom-faint }

![Figure 5]({{site.baseurl}}/assets/images/2022-03-26-visualization.png "Figure 5"){: .align-center}
**Figure 5. Different visualization methods coded in** `pymoo`
{: .custom-caption }

### C. Decision Making

실무적으로는 비지배 솔루션 세트를 얻은 후 그 중 하나의 솔루션을 선택해야 하는 경우가 많다. pymoo는 의사 결정을 위한 몇 가지 "사후적" 접근 방식을 제공한다.

In practice, after obtaining a set of non-dominated solutions a single solution has to be chosen for implementation. pymoo provides a few "a posteriori" approaches for decision making.

(i) 타협 프로그래밍: 결정을 내리는 한 가지 방법은 스칼라화되고 집계된 함수의 값을 계산하고 함수의 최소값 또는 최대값을 기반으로 하나의 솔루션을 선택하는 것이다. pymoo에서는 섹션 VI-D에 설명된 여러 스칼라화 함수를 사용하여 원하는 목표 가중치에 대한 결정을 내릴 수 있다.

(i) Compromise Programming: One way of making a decision is to compute value of a scalarized and aggregated function and select one solution based on minimum or maximum value of the function. In pymoo a number of scalarization functions described in Section VI-D can be used to come to a decision regarding desired weights of objectives.
{: .custom-faint }

(ii) 의사 가중치: 그러나 Pareto-front에서 솔루션을 선택하는 보다 직관적인 방법은 [19]에서 제안된 의사 가중치 벡터 접근 방식<sup>pseudo-weight vector approach</sup>이다. i번째 목적 함수에 대한 의사 가중치 $w_i$는 다음과 같이 계산된다.

(ii) Pseudo-Weights: However, a more intuitive way to chose a solution out of a Pareto-front is the pseudo-weight vector approach proposed in [19]. The pseudo weight wi for the i-th objective function is calculated by:
{: .custom-faint }

$$
\begin{aligned}
  w_i = \frac{(f_i^\max-f_i(x))/(f_i^\max-f_i^\min)}{\sum_{m=1}^M (f_m^\max - f_m(x))/(f_m^\max - f_m^\min)}\\
\end{aligned}
$$

각 목적 i에 관한 최악의 솔루션까지의 정규화된 거리를 계산한다. 볼록하지 않은 파레토 프론트의 경우 의사 가중치가 가중치 합을 사용한 최적화 결과와 일치하지 않는다는 점은 흥미롭다. 목표 선호도 벡터에 가장 가까운 의사 가중치를 갖는 솔루션($f_1$이 $f_2$보다 두 배 더 중요하면 목표 선호 벡터 $(0.667, 0.333)$이 됨)이 efficient set에서 선호 솔루션으로 선택될 수 있습니다.

The normalized distance to the worst solution regarding each objective i is calculated. It is interesting to note that for non-convex Pareto-fronts, the pseudo weight does not correspond to the result of an optimization using the weighted-sum method. A solution having the closest pseudo-weight to a target preference vector of objectives ($f_1$ being preferred twice as important as $f_2$ results in a target preference vector of $(0.667, 0.333)$) can be chosen as the preferred solution from the efficient set.
{: .custom-faint }

(iii) 높은 트레이드 오프 솔루션: 높은 트레이드 오프 솔루션은 보통 관심의 대상이지만 높은 차원의 목표 공간에서 찾기가 쉽지 않다. 우리는 [65]에서 제안한 절차를 구현했다. 이는 탐색 가이드에 포함되는 알고리즘으로 제시되었으나, 우리는 이를 사후 처리에 사용한다. 비지배 집합의 각 솔루션 쌍 $x_i$ 및 $x_j$에 대한 메트릭은 다음과 같다.

(iii) High Trade-Off Solutions: Furthermore, high trade-off solutions are usually of interest, but not straightforward to detect in higher-dimensional objective spaces. We have implemented the procedure proposed in [65]. It was described to be embedded in an algorithm to guide the search; we, however, use it for post-processing. The metric for each solution pair xi and xj in a non-dominated set is given by:
{: .custom-faint }

$$
\begin{aligned}
T(x_i, x_j) = \frac{\sum_{i=1}^M \max[0, f_m(x_j)-f_m(x_i)]}{\sum_{i=1}^M \max[0, f_m(x_i)-f_m(x_j)]}\\
\end{aligned}
$$

여기서 분자는 총 희생을 나타내고 분모는 총 이득을 나타낸다. 일련의 인접 솔루션 S에 대한 각 솔루션 $x_i$에 대한 트레이드-오프 측정값 $\mu(x_i, S)$는 다음과 같이 구한다.

where the numerator represents the aggregated sacrifice and the denominator the aggregated gain. The trade-off measure $\mu(x_i, S)$ for each solution $x_i$ with respect to a set of neighboring solutions S is obtained by:
{: .custom-faint }

$$
\begin{aligned}
\mu(x_i, S) = \min_{x_j \in S} T(x_i, x_j)\\
\end{aligned}
$$

$x_i$으로부터 다른 모든 솔루션 $x_j \in S$의 최소 $T(x_i, x_j)$를 찾는다. 다른 모든 것에 대한 메트릭을 계산하는 대신 계산 복잡성을 줄이기 위해 목적 공간에서 k개의 가장 가까운 이웃만 고려하는 옵션을 제공한다. 상황에 따라 '최소' 연산자는 '평균', '최대' 또는 기타 적절한 연산자로 대체될 수 있다. 그 후, 최대 $\mu$를 갖는 솔루션이 선호 솔루션으로 선택될 수 있다. 이는 이 솔루션이 가장 가치 있는 솔루션에 대한 다른 목표 값에서 단위 이득을 위해 목표 값 중 하나에서 최대 희생을 초래한다는 것을 의미한다. 

It finds the minimum $T(x_i, x_j)$ from $x_i$ to all other solutions $x_j \in S$. Instead of calculating the metric with respect to all others, we provide the option to only consider the k closest neighbors in the objective space to reduce the computational complexity. Based on circumstances, the 'min' operator can be replaced with 'average',or 'max', or any other suitable operator. Thereafter, the solution having the maximum $\mu$ can be chosen as the preferred solution, meaning that this solution causes a maximum sacrifice in one of the objective values for a unit gain in another objective value for it be the most valuable solution for implementation.
{: .custom-faint }

위의 방법은 알고리즘 방식이지만 최선의 솔루션을 선택하려면 사용자와의 상호 작용이 필요하다. 그러나 실제로는 다른 곳에서 제안된 상호작용 EMO 방법과 같이 보다 문제에 특정한 의사결정 방법을 사용해야 한다. 여기서 우리는 다중 목표 프레임워크가 다중 기준 의사 결정을 위한 방법을 포함해야 하고 최종 사용자가 트레이드 오프 솔루션 세트에서 솔루션을 선택할 수 있도록 지원해야 한다는 사실을 강조했다.

The above methods are algorithmic, but requires an user interaction to choose a single preferred solution. However, in real practice, a more problem specific decision-making method must be used, such as an interaction EMO method suggested elsewhere. We emphasize here the fact that multi-objective frameworks should include methods for multi-criteria decision making and support end-user further in choosing a solution out of a trade-off solution set.
{: .custom-faint }

## VIII. Concluding Remarks

생략

J. Blank and K. Deb, "Pymoo: Multi-Objective Optimization in Python," in IEEE Access, vol. 8, pp. 89497-89509, 2020, doi: 10.1109/ACCESS.2020.2990567.
{: .notice--success}